import json
import re
import os
import asyncio
import subprocess
import zipfile
import shutil
import hashlib
import random
import string
import socket
import logging
from datetime import datetime, timedelta
from pathlib import Path
from email.message import EmailMessage
from email import message_from_bytes
import requests
import discord
import boto3
import imaplib
import pandas as pd
import openpyxl
import sqlite3
import mysql.connector
import psycopg2
import psutil
import paramiko
import pyautogui
import cv2
import pyperclip
import speech_recognition as sr
from PIL import Image
import qrcode
from fpdf import FPDF

import matplotlib.pyplot as plt
import seaborn as sns
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from cryptography.fernet import Fernet

# Your existing imports
from Optimind_AI.main import groq_answer
from Optimind_AI.data import *
from google.oauth2.credentials import Credentials
from googleapiclient.http import MediaFileUpload
from googleapiclient.discovery import build
from django.core.mail import send_mail as dj_send_mail
import sys

# Additional imports for new integrations
try:
    import tweepy
    TWITTER_AVAILABLE = True
except ImportError:
    TWITTER_AVAILABLE = False

try:
    import dropbox
    DROPBOX_AVAILABLE = True
except ImportError:
    DROPBOX_AVAILABLE = False

try:
    import docker
    DOCKER_AVAILABLE = True
except ImportError:
    DOCKER_AVAILABLE = False

try:
    import wikipedia
    WIKIPEDIA_AVAILABLE = True
except ImportError:
    WIKIPEDIA_AVAILABLE = False

try:
    import pywhatkit as kit
    PYWHATKIT_AVAILABLE = True
except ImportError:
    PYWHATKIT_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import nmap
    NMAP_AVAILABLE = True
except ImportError:
    NMAP_AVAILABLE = False

try:
    import yfinance
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False

# Create a session for requests
SESSION = requests.Session()
IS_WINDOWS = sys.platform.startswith("win")
IS_MACOS = sys.platform == "darwin"
IS_LINUX = sys.platform.startswith("linux")
# Additional environment variables (add these to your Optimind_AI.data.data)



def extract_params(self, query, service_type):
    """Generic parameter extraction using NLP"""
    prompts = {
        # Original services
        "aws_control": "Extract 'action', 'instance_id', 'region' from query. Return as JSON.",
        "upload_to_google_drive": "Extract 'path', 'filename' from query. Return as JSON.",
        "schedule_google_calendar_event": "Extract 'title', 'start_time', 'end_time' from query. Return as JSON.",
        "send_discord_message": "Extract 'message', 'channel_id' from query. Return as JSON.",
        "send_whatsapp_message": "Extract 'phone', 'message' from query. Return as JSON.",
        "send_email": "Extract 'message', 'recipient_email' from query. Return as JSON.",
        "send_multiple_emails": "Extract 'message', 'emails', 'sender' from query. Return as JSON.",
        "download_email_attachments": "Extract 'email_user', 'email_pass', 'folder' from query. Return as JSON.",
        
        # Communication Integrations
        "send_slack_message": "Extract 'message', 'channel', 'username' from query. Return as JSON.",
        "post_tweet": "Extract 'tweet_text', 'image_path' from query. Return as JSON.",
        "send_telegram_message": "Extract 'chat_id', 'message', 'parse_mode' from query. Return as JSON.",
        
        # Cloud & Infrastructure
        "github_create_repo": "Extract 'repo_name', 'description', 'is_private' from query. Return as JSON.",
        "azure_vm_control": "Extract 'action', 'vm_name', 'resource_group' from query. Return as JSON.",
        "dropbox_upload": "Extract 'local_path', 'remote_path' from query. Return as JSON.",
        "docker_container_control": "Extract 'action', 'container_name', 'image_name' from query. Return as JSON.",
        
        # AI & Processing
        "openai_chat": "Extract 'prompt', 'model', 'max_tokens' from query. Return as JSON.",
        "translate_text": "Extract 'text', 'target_language', 'source_language' from query. Return as JSON.",
        "wikipedia_search": "Extract 'query', 'sentences' from query. Return as JSON.",
        
        # Media & Files
        "youtube_download": "Extract 'url', 'format', 'output_path' from query. Return as JSON.",
        "qr_code_generate": "Extract 'data', 'filename', 'size' from query. Return as JSON.",
        "pdf_create": "Extract 'content', 'filename', 'title' from query. Return as JSON.",
        "screenshot": "Extract 'filename', 'region' from query. Return as JSON.",
        "image_ocr": "Extract 'image_path', 'api_key' from query. Return as JSON.",
        "video_convert": "Extract 'input_path', 'output_path', 'format' from query. Return as JSON.",
        "audio_extract": "Extract 'video_path', 'output_path' from query. Return as JSON.",
        
        # Data & Analysis
        "excel_operations": "Extract 'operation', 'file_path', 'sheet_name' from query. Return as JSON.",
        "database_query": "Extract 'query', 'database_type', 'host' from query. Return as JSON.",
        "data_visualization": "Extract 'data_file', 'chart_type', 'output_file' from query. Return as JSON.",
        "weather_info": "Extract 'city', 'country', 'units' from query. Return as JSON.",
        "stock_price": "Extract 'symbol', 'period', 'interval' from query. Return as JSON.",
        "currency_convert": "Extract 'amount', 'from_currency', 'to_currency' from query. Return as JSON.",
        
        # Security & Utilities
        "encrypt_decrypt_file": "Extract 'operation', 'input_file', 'output_file', 'key' from query. Return as JSON.",
        "password_generate": "Extract 'length', 'include_symbols', 'include_numbers' from query. Return as JSON.",
        "url_shorten": "Extract 'long_url', 'custom_alias' from query. Return as JSON.",
        "domain_lookup": "Extract 'domain_name', 'info_type' from query. Return as JSON.",
        "hash_generate": "Extract 'text', 'algorithm' from query. Return as JSON.",
        
        # System & Network
        "system_info": "Extract 'info_type' from query. Return as JSON.",
        "process_control": "Extract 'action', 'process_name', 'pid' from query. Return as JSON.",
        "backup_files": "Extract 'source', 'destination', 'compression' from query. Return as JSON.",
        "network_scan": "Extract 'target', 'port_range' from query. Return as JSON.",
        "ssh_execute": "Extract 'host', 'command', 'username', 'password' from query. Return as JSON.",
        
        # Automation
        "web_scrape": "Extract 'url', 'element', 'output' from query. Return as JSON.",
        "file_operations": "Extract 'operation', 'path', 'destination' from query. Return as JSON.",
        "git_operations": "Extract 'operation', 'repo_path', 'branch' from query. Return as JSON.",
        "api_test": "Extract 'url', 'method', 'payload' from query. Return as JSON.",
        "log_analyze": "Extract 'log_file', 'pattern', 'output' from query. Return as JSON.",
    }
    
    if service_type in prompts:
        prompt = f"{prompts[service_type]} Query: '{query}'. If a parameter is not mentioned, set it to 'none'. Return ONLY JSON, no explanations."
        nlp_result = groq_answer(prompt)
        try:
            return json.loads(nlp_result)
        except:
            pattern = r'"([^"]+)":\s*"([^"]*)"'
            matches = re.findall(pattern, nlp_result)
            return {k: v for k, v in matches}
    return {}

# ========== ORIGINAL FUNCTIONS ==========

def git_operations(self, query=None):
    """Perform Git operations (clone, pull, push, commit)"""
    if query:
        nlp = self.extract_params(query, "git_operations")
    else:
        nlp = {"operation": "none", "repo_path": "none", "branch": "none", "commit_message": "none"}
    
    operation = nlp["operation"] if nlp["operation"] != "none" else input("Git operation (clone/pull/push/commit/status): ")
    repo_path = nlp["repo_path"] if nlp["repo_path"] != "none" else input("Repository path: ")
    branch = nlp["branch"] if nlp["branch"] != "none" else "main"
    commit_message = nlp["commit_message"] if nlp["commit_message"] != "none" else None
    
    try:
        import git
        
        if operation == "clone":
            url = input("Repository URL: ")
            print(f"Cloning {url} to {repo_path}...")
            git.Repo.clone_from(url, repo_path)
            return f"‚úÖ Repository cloned to {repo_path}"
        
        elif operation == "status":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            status = repo.git.status()
            changes = repo.git.diff('HEAD')
            
            result = f"üìä Git Status for {repo_path}:\n"
            result += f"Branch: {repo.active_branch}\n"
            result += f"Status:\n{status}\n"
            
            if changes:
                result += f"Changes:\n{changes[:500]}..."  # Limit output
            else:
                result += "No changes to commit."
            
            return result
        
        elif operation == "pull":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            origin = repo.remotes.origin
            origin.pull()
            return f"‚úÖ Pulled latest changes from {branch} branch"
        
        elif operation == "push":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            origin = repo.remotes.origin
            
            # Check if there are changes to push
            if repo.is_dirty() or len(repo.untracked_files) > 0:
                return "‚ùå There are uncommitted changes. Commit first before pushing."
            
            origin.push()
            return f"‚úÖ Pushed changes to {branch} branch"
        
        elif operation == "commit":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            
            # Check for changes
            if not repo.is_dirty() and len(repo.untracked_files) == 0:
                return "‚ùå No changes to commit"
            
            # If no commit message provided in query, ask for one
            if not commit_message:
                commit_message = input("Enter commit message: ")
            
            if not commit_message.strip():
                return "‚ùå Commit message is required"
            
            # Add all changes
            repo.git.add(A=True)
            
            # Commit
            repo.index.commit(commit_message)
            
            # Get commit info
            commit = repo.head.commit
            
            result = f"‚úÖ Committed changes:\n"
            result += f"Message: {commit_message}\n"
            result += f"Commit Hash: {commit.hexsha[:8]}\n"
            result += f"Author: {commit.author.name}\n"
            result += f"Date: {commit.authored_datetime}\n"
            
            # Show what was changed
            diff = repo.git.diff('HEAD~1', 'HEAD')
            if diff:
                result += f"\nChanges:\n{diff[:300]}..."  # Limit output
            
            return result
        
        elif operation == "branch":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            action = input("Branch action (create/list/switch/delete): ")
            
            if action == "list":
                branches = [str(b) for b in repo.branches]
                current = repo.active_branch
                result = f"üåø Branches in {repo_path}:\n"
                result += f"Current: {current}\n"
                result += "All branches:\n" + "\n".join(branches)
                return result
            
            elif action == "create":
                new_branch = input("New branch name: ")
                repo.git.checkout('-b', new_branch)
                return f"‚úÖ Created and switched to branch: {new_branch}"
            
            elif action == "switch":
                branch_name = input("Branch to switch to: ")
                repo.git.checkout(branch_name)
                return f"‚úÖ Switched to branch: {branch_name}"
            
            elif action == "delete":
                branch_name = input("Branch to delete: ")
                if branch_name == repo.active_branch:
                    return f"‚ùå Cannot delete current branch. Switch to another branch first."
                repo.git.branch('-d', branch_name)
                return f"‚úÖ Deleted branch: {branch_name}"
            
            else:
                return "‚ùå Invalid branch action"
        
        elif operation == "log":
            if not os.path.exists(repo_path):
                return "‚ùå Repository path does not exist"
            
            repo = git.Repo(repo_path)
            limit = input("Number of commits to show (default 10): ") or "10"
            
            try:
                limit_int = int(limit)
            except:
                limit_int = 10
            
            commits = list(repo.iter_commits(max_count=limit_int))
            
            result = f"üìú Last {len(commits)} commits in {repo_path}:\n"
            for i, commit in enumerate(commits):
                result += f"\n{i+1}. {commit.hexsha[:8]} - {commit.summary}\n"
                result += f"   Author: {commit.author.name} <{commit.author.email}>\n"
                result += f"   Date: {commit.authored_datetime.strftime('%Y-%m-%d %H:%M')}\n"
            
            return result
        
        else:
            return "‚ùå Invalid operation. Use: clone, status, pull, push, commit, branch, log"
        
    except ImportError:
        return "‚ùå GitPython not installed. Run: pip install gitpython"
    except git.InvalidGitRepositoryError:
        return f"‚ùå Not a valid Git repository: {repo_path}"
    except git.GitCommandError as e:
        return f"‚ùå Git command failed: {e}"
    except Exception as e:
        return f"‚ùå Git operation failed: {e}"

def translate_text(self, query=None):
    """Translate text between languages using Google Translate"""
    if query:
        nlp = self.extract_params(query, "translate_text")
    else:
        nlp = {"text": "none", "target_language": "none", "source_language": "none"}
    
    text = nlp["text"] if nlp["text"] != "none" else input("Text to translate: ")
    target_lang = nlp["target_language"] if nlp["target_language"] != "none" else input("Target language (e.g., es, fr, de, ja): ")
    source_lang = nlp["source_language"] if nlp["source_language"] != "none" else "auto"
    
    try:
        # Try googletrans first (more reliable)
        try:
            from googletrans import Translator
            translator = Translator()
            result = translator.translate(text, dest=target_lang, src=source_lang)
            
            translation = result.text
            detected_lang = result.src
            confidence = getattr(result, 'confidence', 'N/A')
            
            result_str = f"üåê Translation:\n"
            result_str += f"üìù Original ({detected_lang}): {text}\n"
            result_str += f"üî§ Translated ({target_lang}): {translation}\n"
            if confidence != 'N/A':
                result_str += f"üìä Confidence: {confidence*100:.1f}%\n"
            
            # Show pronunciation if available
            if hasattr(result, 'pronunciation') and result.pronunciation:
                result_str += f"üó£Ô∏è Pronunciation: {result.pronunciation}\n"
            
            return result_str
            
        except ImportError:
            # Fallback to Google Translate API (requires API key)
            if not GOOGLE_TRANSLATE_API_KEY:
                return "‚ùå Google Translate API key not set in environment variables.\nInstall: pip install googletrans==4.0.0rc1"
            
            import json
            from urllib.parse import quote
            
            # Encode text for URL
            encoded_text = quote(text)
            
            # Build URL for Google Translate API
            url = f"https://translation.googleapis.com/language/translate/v2"
            params = {
                'q': text,
                'target': target_lang,
                'format': 'text',
                'key': GOOGLE_TRANSLATE_API_KEY
            }
            
            if source_lang != 'auto':
                params['source'] = source_lang
            
            response = requests.post(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                translation = data['data']['translations'][0]['translatedText']
                detected_lang = data['data']['translations'][0].get('detectedSourceLanguage', 'auto')
                
                result_str = f"üåê Translation:\n"
                result_str += f"üìù Original ({detected_lang}): {text}\n"
                result_str += f"üî§ Translated ({target_lang}): {translation}\n"
                return result_str
            else:
                return f"‚ùå Translation failed: {response.text}"
                
    except Exception as e:
        return f"‚ùå Translation failed: {e}"

# Also add this helper function for language detection
def detect_language(self, query=None):
    """Detect the language of text"""
    if query:
        nlp = self.extract_params(query, "detect_language")
    else:
        nlp = {"text": "none"}
    
    text = nlp["text"] if nlp["text"] != "none" else input("Text to analyze: ")
    
    try:
        from googletrans import Translator
        translator = Translator()
        result = translator.detect(text)
        
        result_str = f"üîç Language Detection:\n"
        result_str += f"üìù Text: {text}\n"
        result_str += f"üåê Detected Language: {result.lang} ({self.get_language_name(result.lang)})\n"
        result_str += f"üìä Confidence: {result.confidence*100:.1f}%\n"
        
        return result_str
        
    except ImportError:
        return "‚ùå Install: pip install googletrans==4.0.0rc1"
    except Exception as e:
        return f"‚ùå Language detection failed: {e}"

# Helper function to get language name from code
def get_language_name(self, lang_code):
    """Convert language code to full name"""
    language_names = {
        'af': 'Afrikaans', 'sq': 'Albanian', 'am': 'Amharic', 'ar': 'Arabic',
        'hy': 'Armenian', 'az': 'Azerbaijani', 'eu': 'Basque', 'be': 'Belarusian',
        'bn': 'Bengali', 'bs': 'Bosnian', 'bg': 'Bulgarian', 'ca': 'Catalan',
        'ceb': 'Cebuano', 'ny': 'Chichewa', 'zh-cn': 'Chinese (Simplified)',
        'zh-tw': 'Chinese (Traditional)', 'co': 'Corsican', 'hr': 'Croatian',
        'cs': 'Czech', 'da': 'Danish', 'nl': 'Dutch', 'en': 'English',
        'eo': 'Esperanto', 'et': 'Estonian', 'tl': 'Filipino', 'fi': 'Finnish',
        'fr': 'French', 'fy': 'Frisian', 'gl': 'Galician', 'ka': 'Georgian',
        'de': 'German', 'el': 'Greek', 'gu': 'Gujarati', 'ht': 'Haitian Creole',
        'ha': 'Hausa', 'haw': 'Hawaiian', 'he': 'Hebrew', 'hi': 'Hindi',
        'hmn': 'Hmong', 'hu': 'Hungarian', 'is': 'Icelandic', 'ig': 'Igbo',
        'id': 'Indonesian', 'ga': 'Irish', 'it': 'Italian', 'ja': 'Japanese',
        'jw': 'Javanese', 'kn': 'Kannada', 'kk': 'Kazakh', 'km': 'Khmer',
        'ko': 'Korean', 'ku': 'Kurdish (Kurmanji)', 'ky': 'Kyrgyz', 'lo': 'Lao',
        'la': 'Latin', 'lv': 'Latvian', 'lt': 'Lithuanian', 'lb': 'Luxembourgish',
        'mk': 'Macedonian', 'mg': 'Malagasy', 'ms': 'Malay', 'ml': 'Malayalam',
        'mt': 'Maltese', 'mi': 'Maori', 'mr': 'Marathi', 'mn': 'Mongolian',
        'my': 'Myanmar (Burmese)', 'ne': 'Nepali', 'no': 'Norwegian',
        'ps': 'Pashto', 'fa': 'Persian', 'pl': 'Polish', 'pt': 'Portuguese',
        'pa': 'Punjabi', 'ro': 'Romanian', 'ru': 'Russian', 'sm': 'Samoan',
        'gd': 'Scots Gaelic', 'sr': 'Serbian', 'st': 'Sesotho', 'sn': 'Shona',
        'sd': 'Sindhi', 'si': 'Sinhala', 'sk': 'Slovak', 'sl': 'Slovenian',
        'so': 'Somali', 'es': 'Spanish', 'su': 'Sundanese', 'sw': 'Swahili',
        'sv': 'Swedish', 'tg': 'Tajik', 'ta': 'Tamil', 'te': 'Telugu',
        'th': 'Thai', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu',
        'uz': 'Uzbek', 'vi': 'Vietnamese', 'cy': 'Welsh', 'xh': 'Xhosa',
        'yi': 'Yiddish', 'yo': 'Yoruba', 'zu': 'Zulu'
    }
    return language_names.get(lang_code.lower(), lang_code)

def pdf_create(self, query=None):
    """Create PDF files from text, images, or HTML"""
    if query:
        nlp = self.extract_params(query, "pdf_create")
    else:
        nlp = {"content": "none", "filename": "none", "title": "none", "content_type": "none"}
    
    content = nlp["content"] if nlp["content"] != "none" else input("Enter content (text, HTML, or image path): ")
    filename = nlp["filename"] if nlp["filename"] != "none" else f"document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    title = nlp["title"] if nlp["title"] != "none" else "Generated Document"
    content_type = nlp["content_type"] if nlp["content_type"] != "none" else "auto"
    
    try:
        from fpdf import FPDF
        import tempfile
        
        # Ensure filename has .pdf extension
        if not filename.lower().endswith('.pdf'):
            filename += '.pdf'
        
        # Determine content type automatically
        if content_type == "auto":
            if content.lower().startswith('<html') or content.lower().startswith('<!doctype'):
                content_type = "html"
            elif os.path.exists(content) and content.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                content_type = "image"
            else:
                content_type = "text"
        
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        pdf.add_page()
        
        # Set font for text content
        pdf.set_font("Arial", size=12)
        
        if content_type == "text":
            # Add title if provided
            if title and title != "Generated Document":
                pdf.set_font("Arial", 'B', 16)
                pdf.cell(200, 10, txt=title, ln=1, align='C')
                pdf.set_font("Arial", size=12)
                pdf.ln(10)
            
            # Add metadata
            pdf.set_title(title)
            pdf.set_author("Optimind AI")
            pdf.set_subject("AI Generated Document")
            
            # Split text into lines and add to PDF
            lines = content.split('\n')
            for line in lines:
                if line.strip():  # Only add non-empty lines
                    # Handle long lines by wrapping
                    if pdf.get_string_width(line) > 180:
                        # Simple line wrapping
                        words = line.split(' ')
                        current_line = ""
                        for word in words:
                            if pdf.get_string_width(current_line + " " + word) < 180:
                                current_line += " " + word
                            else:
                                pdf.cell(200, 10, txt=current_line.strip(), ln=1)
                                current_line = word
                        if current_line:
                            pdf.cell(200, 10, txt=current_line.strip(), ln=1)
                    else:
                        pdf.cell(200, 10, txt=line, ln=1)
            
            pdf.ln(10)
            pdf.set_font("Arial", 'I', 10)
            pdf.cell(200, 10, txt=f"Generated by Optimind AI on {datetime.now().strftime('%Y-%m-%d %H:%M')}", ln=1, align='C')
        
        elif content_type == "html":
            # HTML to PDF conversion
            try:
                # Try using xhtml2pdf (better HTML support)
                try:
                    from xhtml2pdf import pisa
                    
                    # Create temporary HTML file
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                        html_content = f"""
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <meta charset="UTF-8">
                            <title>{title}</title>
                            <style>
                                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                                h1 {{ color: #333; }}
                                p {{ line-height: 1.6; }}
                                .footer {{ margin-top: 50px; font-style: italic; color: #666; text-align: center; }}
                            </style>
                        </head>
                        <body>
                            <h1>{title}</h1>
                            {content if content.startswith('<') else f'<p>{content}</p>'}
                            <div class="footer">
                                Generated by Optimind AI on {datetime.now().strftime('%Y-%m-%d %H:%M')}
                            </div>
                        </body>
                        </html>
                        """
                        f.write(html_content)
                        html_file = f.name
                    
                    # Convert HTML to PDF
                    with open(filename, 'wb') as pdf_file:
                        pisa_status = pisa.CreatePDF(
                            open(html_file, 'r', encoding='utf-8').read(),
                            dest=pdf_file
                        )
                    
                    # Clean up temporary file
                    os.unlink(html_file)
                    
                    if pisa_status.err:
                        return f"‚ùå HTML to PDF conversion failed: {pisa_status.err}"
                    
                    return f"‚úÖ PDF created from HTML: {filename}"
                    
                except ImportError:
                    # Fallback: simple HTML parsing
                    from html.parser import HTMLParser
                    
                    class SimpleHTMLParser(HTMLParser):
                        def __init__(self, pdf):
                            super().__init__()
                            self.pdf = pdf
                            self.current_text = ""
                            self.in_body = False
                        
                        def handle_starttag(self, tag, attrs):
                            if tag == 'body':
                                self.in_body = True
                            elif tag in ['br', 'p', 'div'] and self.current_text:
                                self._add_text()
                        
                        def handle_endtag(self, tag):
                            if tag == 'body':
                                self.in_body = False
                            if tag in ['p', 'div', 'br']:
                                self._add_text()
                                self.pdf.ln(5)
                        
                        def handle_data(self, data):
                            if self.in_body:
                                self.current_text += data
                        
                        def _add_text(self):
                            if self.current_text.strip():
                                self.pdf.multi_cell(0, 10, self.current_text.strip())
                                self.current_text = ""
                    
                    # Parse HTML and add to PDF
                    parser = SimpleHTMLParser(pdf)
                    parser.feed(content)
                    parser._add_text()  # Add any remaining text
                    
                    pdf.ln(10)
                    pdf.set_font("Arial", 'I', 10)
                    pdf.cell(200, 10, txt=f"Generated by Optimind AI on {datetime.now().strftime('%Y-%m-%d %H:%M')}", ln=1, align='C')
                    
            except Exception as e:
                return f"‚ùå HTML processing failed: {e}"
        
        elif content_type == "image":
            # Add image to PDF
            if not os.path.exists(content):
                return f"‚ùå Image file not found: {content}"
            
            try:
                from PIL import Image
                
                # Open and get image dimensions
                img = Image.open(content)
                img_width, img_height = img.size
                
                # Calculate dimensions to fit on page (A4: 210x297 mm)
                max_width = 180  # mm
                max_height = 250  # mm
                
                # Calculate scaling factor
                width_scale = max_width / (img_width / 10)  # Convert pixels to mm (approx)
                height_scale = max_height / (img_height / 10)
                scale = min(width_scale, height_scale)
                
                # Calculate final dimensions
                final_width = (img_width / 10) * scale
                final_height = (img_height / 10) * scale
                
                # Add title
                pdf.set_font("Arial", 'B', 16)
                pdf.cell(200, 10, txt=title, ln=1, align='C')
                pdf.ln(10)
                
                # Add image
                pdf.image(content, x=(210 - final_width) / 2, y=None, w=final_width, h=final_height)
                
                # Add caption
                pdf.ln(final_height + 5)
                pdf.set_font("Arial", 'I', 10)
                pdf.cell(200, 10, txt=os.path.basename(content), ln=1, align='C')
                
                # Add footer
                pdf.ln(10)
                pdf.cell(200, 10, txt=f"Generated by Optimind AI on {datetime.now().strftime('%Y-%m-%d %H:%M')}", ln=1, align='C')
                
            except Exception as e:
                return f"‚ùå Image processing failed: {e}"
        
        elif content_type == "multi":
            # Multiple pages with different content types
            pages_input = input("Enter number of pages: ")
            try:
                num_pages = int(pages_input)
            except:
                num_pages = 1
            
            for page_num in range(num_pages):
                pdf.add_page()
                pdf.set_font("Arial", 'B', 14)
                pdf.cell(200, 10, txt=f"{title} - Page {page_num + 1}", ln=1, align='C')
                pdf.ln(10)
                pdf.set_font("Arial", size=12)
                pdf.multi_cell(0, 10, f"This is page {page_num + 1} of {num_pages}.\n\nSample content for automated PDF generation.")
            
            pdf.ln(10)
            pdf.set_font("Arial", 'I', 10)
            pdf.cell(200, 10, txt=f"Generated by Optimind AI on {datetime.now().strftime('%Y-%m-%d %H:%M')}", ln=1, align='C')
        
        else:
            return f"‚ùå Unsupported content type: {content_type}"
        
        # Save PDF
        pdf.output(filename)
        
        file_size = os.path.getsize(filename) / 1024  # Size in KB
        
        result = f"‚úÖ PDF created successfully!\n"
        result += f"üìÑ File: {filename}\n"
        result += f"üìè Size: {file_size:.1f} KB\n"
        result += f"üìã Type: {content_type.upper()}\n"
        result += f"üè∑Ô∏è Title: {title}\n"
        
        # Offer to open the file
        open_file = input("Open PDF file? (y/n): ").lower()
        if open_file in ['y', 'yes']:
            try:
                if IS_WINDOWS:
                    os.startfile(filename)
                elif IS_MACOS:
                    subprocess.run(["open", filename])
                elif IS_LINUX:
                    subprocess.run(["xdg-open", filename])
                result += f"\nüìÇ File opened!"
            except:
                result += f"\nCould not open file automatically"
        
        return result
        
    except ImportError as e:
        return f"‚ùå Required library not found: {e}\nInstall: pip install fpdf pillow"
    except Exception as e:
        return f"‚ùå PDF creation failed: {e}"

def docker_container_control(self, query=None):
    """Control Docker containers (start, stop, restart, run, list, logs)"""
    if query:
        nlp = self.extract_params(query, "docker_container_control")
    else:
        nlp = {"action": "none", "container_name": "none", "image_name": "none", "port": "none"}
    
    action = nlp["action"] if nlp["action"] != "none" else input("Action (start/stop/restart/run/list/logs/inspect/remove): ")
    container_name = nlp["container_name"] if nlp["container_name"] != "none" else None
    image_name = nlp["image_name"] if nlp["image_name"] != "none" else None
    port = nlp["port"] if nlp["port"] != "none" else None
    
    try:
        if not DOCKER_AVAILABLE:
            return "‚ùå Docker not installed. Run: pip install docker"
        
        client = docker.from_env()
        
        if action == "list":
            # List all containers
            containers = client.containers.list(all=True)
            
            if not containers:
                return "üì¶ No Docker containers found"
            
            result = f"üê≥ Docker Containers ({len(containers)} total):\n"
            result += "=" * 60 + "\n"
            
            for container in containers:
                status = "üü¢ Running" if container.status == "running" else "üî¥ Stopped"
                name = container.name
                image = container.attrs['Config']['Image']
                container_id = container.short_id
                
                # Get ports
                ports_info = container.attrs['NetworkSettings']['Ports'] or {}
                ports = []
                for host_port, guest_ports in ports_info.items():
                    if guest_ports:
                        for guest in guest_ports:
                            ports.append(f"{guest['HostPort']}->{host_port}")
                
                ports_str = ", ".join(ports) if ports else "No ports"
                
                result += f"üìõ Name: {name}\n"
                result += f"   ID: {container_id}\n"
                result += f"   Status: {status}\n"
                result += f"   Image: {image}\n"
                result += f"   Ports: {ports_str}\n"
                result += f"   Created: {container.attrs['Created'][:19].replace('T', ' ')}\n"
                result += "-" * 60 + "\n"
            
            return result
        
        elif action == "run":
            if not image_name:
                image_name = input("Docker image name (e.g., nginx:latest): ")
            
            if not container_name:
                container_name = input("Container name (optional, press Enter for auto): ") or None
            
            port_mapping = {}
            if port:
                if ":" in port:
                    host_port, container_port = port.split(":")
                    port_mapping[f"{container_port}/tcp"] = int(host_port)
                else:
                    port_mapping[f"{port}/tcp"] = int(port)
            else:
                port_input = input("Port mapping (e.g., 8080:80 or press Enter for none): ")
                if port_input and ":" in port_input:
                    host_port, container_port = port_input.split(":")
                    port_mapping[f"{container_port}/tcp"] = int(host_port)
            
            # Ask for additional options
            detach = input("Run in background? (y/n, default: y): ").lower() not in ['n', 'no']
            auto_remove = input("Auto remove when stopped? (y/n, default: n): ").lower() in ['y', 'yes']
            
            print(f"üöÄ Running container from {image_name}...")
            
            container = client.containers.run(
                image=image_name,
                name=container_name,
                ports=port_mapping if port_mapping else None,
                detach=detach,
                auto_remove=auto_remove
            )
            
            result = f"‚úÖ Container started:\n"
            result += f"   Name: {container.name}\n"
            result += f"   ID: {container.short_id}\n"
            result += f"   Image: {image_name}\n"
            if port_mapping:
                result += f"   Ports: {port_mapping}\n"
            
            if not detach:
                # If not detached, wait and show logs
                print("Container running (press Ctrl+C to stop)...")
                try:
                    for line in container.logs(stream=True):
                        print(line.decode().strip())
                except KeyboardInterrupt:
                    container.stop()
                    result += "\n‚èπÔ∏è Container stopped by user"
            
            return result
        
        elif action == "start":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            try:
                container = client.containers.get(container_name)
                container.start()
                return f"‚úÖ Container {container_name} started"
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to start container: {e}"
        
        elif action == "stop":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            try:
                container = client.containers.get(container_name)
                container.stop()
                return f"‚úÖ Container {container_name} stopped"
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to stop container: {e}"
        
        elif action == "restart":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            try:
                container = client.containers.get(container_name)
                container.restart()
                return f"‚úÖ Container {container_name} restarted"
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to restart container: {e}"
        
        elif action == "logs":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            try:
                container = client.containers.get(container_name)
                logs = container.logs(tail=100).decode('utf-8')
                
                if not logs.strip():
                    return f"üìÑ No logs available for {container_name}"
                
                result = f"üìÑ Logs for {container_name} (last 100 lines):\n"
                result += "=" * 60 + "\n"
                result += logs[:2000]  # Limit output
                if len(logs) > 2000:
                    result += "\n... (truncated, showing first 2000 characters)"
                
                return result
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to get logs: {e}"
        
        elif action == "inspect":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            try:
                container = client.containers.get(container_name)
                inspect_data = container.attrs
                
                result = f"üîç Inspection for {container_name}:\n"
                result += "=" * 60 + "\n"
                result += f"üìõ Name: {inspect_data['Name'].lstrip('/')}\n"
                result += f"üÜî ID: {inspect_data['Id'][:12]}\n"
                result += f"üìä Status: {inspect_data['State']['Status']}\n"
                result += f"üèÉ Running: {inspect_data['State']['Running']}\n"
                result += f"üê≥ Image: {inspect_data['Config']['Image']}\n"
                
                # Network info
                networks = inspect_data['NetworkSettings']['Networks']
                if networks:
                    for network_name, network_info in networks.items():
                        result += f"üåê Network: {network_name} (IP: {network_info['IPAddress']})\n"
                
                # Ports
                ports = inspect_data['NetworkSettings']['Ports']
                if ports:
                    result += "üîå Ports:\n"
                    for container_port, host_ports in ports.items():
                        if host_ports:
                            for host in host_ports:
                                result += f"   {host['HostPort']}->{container_port}\n"
                
                # Mounts
                mounts = inspect_data['Mounts']
                if mounts:
                    result += "üìÇ Mounts:\n"
                    for mount in mounts:
                        result += f"   {mount['Source']} -> {mount['Destination']}\n"
                
                # Environment variables
                env_vars = inspect_data['Config']['Env']
                if env_vars:
                    result += "‚öôÔ∏è Environment variables:\n"
                    for env in env_vars[:5]:  # Show first 5
                        result += f"   {env}\n"
                    if len(env_vars) > 5:
                        result += f"   ... and {len(env_vars)-5} more\n"
                
                return result
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
        
        elif action == "remove":
            if not container_name:
                container_name = input("Container name or ID: ")
            
            force = input("Force remove? (y/n, default: n): ").lower() in ['y', 'yes']
            
            try:
                container = client.containers.get(container_name)
                
                if container.status == "running" and not force:
                    return f"‚ùå Container {container_name} is running. Use force remove or stop it first."
                
                container.remove(force=force)
                return f"‚úÖ Container {container_name} removed"
            except docker.errors.NotFound:
                return f"‚ùå Container {container_name} not found"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to remove container: {e}"
        
        elif action == "images":
            # List Docker images
            images = client.images.list()
            
            if not images:
                return "üì¶ No Docker images found"
            
            result = f"üê≥ Docker Images ({len(images)} total):\n"
            result += "=" * 60 + "\n"
            
            for image in images:
                tags = image.tags
                image_id = image.short_id
                created = image.attrs['Created'][:19].replace('T', ' ')
                size_mb = image.attrs['Size'] / (1024 * 1024)
                
                result += f"üì¶ Tags: {', '.join(tags) if tags else '<none>'}\n"
                result += f"   ID: {image_id}\n"
                result += f"   Size: {size_mb:.1f} MB\n"
                result += f"   Created: {created}\n"
                result += "-" * 60 + "\n"
            
            return result
        
        elif action == "pull":
            if not image_name:
                image_name = input("Image to pull (e.g., nginx:latest): ")
            
            print(f"‚¨áÔ∏è Pulling {image_name}...")
            try:
                image = client.images.pull(image_name)
                return f"‚úÖ Pulled {image_name}\nTags: {', '.join(image.tags)}"
            except docker.errors.APIError as e:
                return f"‚ùå Failed to pull image: {e}"
        
        else:
            return "‚ùå Invalid action. Use: list, run, start, stop, restart, logs, inspect, remove, images, pull"
        
    except Exception as e:
        return f"‚ùå Docker operation failed: {e}"

def aws_control(self, query=None):
    """Control AWS EC2 instances"""
    if query:
        nlp = self.extract_params(query, "aws_control")
    else:
        nlp = {"action": "none", "instance_id": "none", "region": "none"}
    
    action = nlp["action"] if nlp["action"] != "none" else input("Type in the Action (start/stop): ")
    instance_id = nlp["instance_id"] if nlp["instance_id"] != "none" else input("Type in the Instance ID: ")
    region = nlp["region"] if nlp["region"] != "none" else "us-east-1"
    
    try:
        ec2 = boto3.client("ec2", region_name=region)
        if action.lower() == "start":
            ec2.start_instances(InstanceIds=[instance_id])
            return f"‚úÖ EC2 instance {instance_id} started in {region}"
        elif action.lower() == "stop":
            ec2.stop_instances(InstanceIds=[instance_id])
            return f"‚úÖ EC2 instance {instance_id} stopped in {region}"
        else:
            return "‚ùå Action must be 'start' or 'stop'"
    except Exception as e:
        return f"‚ùå Failed to control EC2 instance: {e}"

def upload_to_google_drive(self, query=None):
    """Upload file to Google Drive"""
    if query:
        nlp = self.extract_params(query, "upload_to_google_drive")
    else:
        nlp = {"path": "none", "filename": "none"}
    
    path = nlp["path"] if nlp["path"] != "none" else input("Enter the file path: ")
    custom_name = nlp["filename"] if nlp["filename"] != "none" else input("Enter custom filename (press Enter for original): ") or None
    
    if not os.path.exists(path):
        return "‚ùå File not found"
    
    filename = custom_name or os.path.basename(path)
    
    try:
        creds = Credentials.from_authorized_user_file(
            "google_token.json", ["https://www.googleapis.com/auth/drive"]
        )
        service = build("drive", "v3", credentials=creds)
        
        media = MediaFileUpload(path, resumable=True)
        file = service.files().create(
            body={"name": filename},
            media_body=media
        ).execute()
        
        return f"‚úÖ Uploaded '{filename}' to Google Drive. File ID: {file.get('id', 'No ID returned')}"
    except FileNotFoundError:
        return "‚ùå google_token.json not found"
    except Exception as e:
        return f"‚ùå Failed to upload file: {e}"

def schedule_google_calendar_event(self, query=None):
    """Schedule Google Calendar event"""
    if query:
        nlp = self.extract_params(query, "schedule_google_calendar_event")
    else:
        nlp = {"title": "none", "start_time": "none", "end_time": "none"}
    
    title = nlp["title"] if nlp["title"] != "none" else input("Enter the event title: ")
    start_time = nlp["start_time"] if nlp["start_time"] != "none" else input("Enter the start time (YYYY-MM-DD HH:MM): ")
    end_time = nlp["end_time"] if nlp["end_time"] != "none" else input("Enter the end time (YYYY-MM-DD HH:MM): ")
    
    try:
        creds = Credentials.from_authorized_user_file(
            "google_token.json", 
            ["https://www.googleapis.com/auth/calendar"]
        )
        service = build("calendar", "v3", credentials=creds)
        
        event = {
            "summary": title or "AI Event",
            "start": {"dateTime": f"{start_time}:00", "timeZone": "UTC"},
            "end": {"dateTime": f"{end_time}:00", "timeZone": "UTC"}
        }
        
        service.events().insert(calendarId="primary", body=event).execute()
        return f"‚úÖ Calendar event '{title}' created successfully"
    except FileNotFoundError:
        return "‚ùå google_token.json file not found."
    except Exception as e:
        return f"‚ùå Failed to create calendar event: {e}"

def send_discord_message(self, query=None):
    """Send Discord message"""
    if query:
        nlp = self.extract_params(query, "send_discord_message")
    else:
        nlp = {"message": "none", "channel_id": "none"}
    
    message = nlp["message"] if nlp["message"] != "none" else input("Enter the message to send: ")
    channel_id = int(nlp["channel_id"]) if nlp["channel_id"] != "none" else int(input("Enter the channel ID to send to: "))
    
    if not message:
        return "‚ùå Message is required."
    
    async def _discord_send(channel_id_inner, message_inner):
        intents = discord.Intents.default()
        client = discord.Client(intents=intents)
        
        @client.event
        async def on_ready():
            try:
                channel = client.get_channel(channel_id_inner)
                if channel:
                    await channel.send(message_inner)
                    print(f"‚úÖ Discord message sent to channel {channel_id_inner}")
                else:
                    print(f"‚ùå Channel {channel_id_inner} not found")
            except Exception as e:
                print(f"Discord send failed: {e}")
            finally:
                await client.close()
        
        try:
            await client.start(DISCORD_TOKEN)
        except Exception as e:
            print(f"Discord client failed to start: {e}")
    
    try:
        asyncio.run(_discord_send(channel_id, message))
        return f"‚úÖ Discord message sent to channel {channel_id}"
    except Exception as e:
        return f"‚ùå Failed to send Discord message: {e}"

def send_whatsapp_message(self, query=None):
    """Send WhatsApp message"""
    if query:
        nlp = self.extract_params(query, "send_whatsapp_message")
    else:
        nlp = {"phone": "none", "message": "none"}
    
    phone = nlp["phone"] if nlp["phone"] != "none" else input("Enter the phone number to send to: ")
    message = nlp["message"] if nlp["message"] != "none" else input("Enter the message to send: ")
    
    if not WHATSAPP_TOKEN or not WHATSAPP_PHONE_ID:
        return "‚ùå WhatsApp credentials not set in environment variables."
    
    if not phone or not message:
        return "‚ùå Phone number and message are required."
    
    url = f"https://graph.facebook.com/v18.0/{WHATSAPP_PHONE_ID}/messages"
    headers = {
        "Authorization": f"Bearer {WHATSAPP_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "messaging_product": "whatsapp",
        "to": phone,
        "type": "text",
        "text": {"body": message}
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        if response.ok:
            return f"‚úÖ WhatsApp message sent to {phone}"
        else:
            return f"‚ùå Failed to send message: {response.text}"
    except Exception as e:
        return f"‚ùå Failed to send WhatsApp message: {e}"

def send_email(self, query=None):
    """Send single email"""
    if query:
        nlp = self.extract_params(query, "send_email")
    else:
        nlp = {"message": "none", "recipient_email": "none"}
    
    message = nlp["message"] if nlp["message"] != "none" else input("Enter the message to send: ")
    recipient_email = nlp["recipient_email"] if nlp["recipient_email"] != "none" else input("Enter the recipient's email: ")
    
    if not message or not recipient_email:
        return "‚ùå Missing message or recipient email."
    
    try:
        dj_send_mail(
            subject="AI Notification",
            message=message,
            from_email="ai@example.com",
            recipient_list=[recipient_email],
            fail_silently=False
        )
        return f"‚úÖ Email sent to {recipient_email}"
    except Exception as e:
        return f"‚ùå Failed to send email to {recipient_email}: {e}"

def send_multiple_emails(self, query=None):
    """Send emails to multiple recipients"""
    if query:
        nlp = self.extract_params(query, "send_multiple_emails")
    else:
        nlp = {"message": "none", "emails": "none", "sender": "none"}
    
    message = nlp["message"] if nlp["message"] != "none" else input("Enter the message to send: ")
    emails_string = nlp["emails"] if nlp["emails"] != "none" else input("Enter a comma-separated list of recipient emails: ")
    sender = nlp["sender"] if nlp["sender"] != "none" else input("Enter the sender's email: ")
    
    if not message or not emails_string:
        return "‚ùå Missing message or recipient emails."
    
    emails = [e.strip() for e in emails_string.split(",") if e.strip()]
    results = []
    
    for email_addr in emails:
        try:
            dj_send_mail(
                subject="AI Notification",
                message=message,
                from_email=sender,
                recipient_list=[email_addr],
                fail_silently=False
            )
            results.append(f"‚úÖ Email sent to {email_addr}")
        except Exception as e:
            results.append(f"‚ùå Failed to send to {email_addr}: {e}")
    
    return "\n".join(results)

def download_email_attachments(self, query=None):
    """Download email attachments"""
    if query:
        nlp = self.extract_params(query, "download_email_attachments")
    else:
        nlp = {"email_user": "none", "email_pass": "none", "folder": "none"}
    
    email_user = nlp["email_user"] if nlp["email_user"] != "none" else input("Enter your email username: ")
    email_pass = nlp["email_pass"] if nlp["email_pass"] != "none" else input("Enter your email password: ")
    folder = nlp["folder"] if nlp["folder"] != "none" else "attachments"
    
    if not email_user or not email_pass:
        return "‚ùå Email username and password required."
    
    try:
        mail = imaplib.IMAP4_SSL("imap.gmail.com")
        mail.login(email_user, email_pass)
        mail.select("inbox")
        
        _, data = mail.search(None, "ALL")
        
        os.makedirs(folder, exist_ok=True)
        downloaded_count = 0
        
        for num in data[0].split():
            _, msg_data = mail.fetch(num, "(RFC822)")
            msg = message_from_bytes(msg_data[0][1])
            
            for part in msg.walk():
                filename = part.get_filename()
                if filename:
                    filepath = os.path.join(folder, filename)
                    with open(filepath, "wb") as f:
                        f.write(part.get_payload(decode=True))
                    downloaded_count += 1
        
        mail.close()
        mail.logout()
        
        return f"‚úÖ Downloaded {downloaded_count} attachments to '{folder}' folder"
    except Exception as e:
        return f"‚ùå Failed to download attachments: {e}"

# ========== OCR FUNCTION ==========

def image_ocr(self, query=None):
    """Perform OCR on an image using OCR.Space API"""
    if query:
        nlp = self.extract_params(query, "image_ocr")
    else:
        nlp = {"image_path": "none", "api_key": "none"}
    
    image_path = nlp["image_path"] if nlp["image_path"] != "none" else input("Enter image path: ")
    api_key = nlp["api_key"] if nlp["api_key"] != "none" else "K85328613788957"
    
    if not image_path:
        return "Error: No image path provided."
    
    p = Path(image_path)
    if not p.exists():
        return "Error: image not found."
    
    try:
        with p.open("rb") as img_file:
            r = SESSION.post(
                "https://api.ocr.space/parse/image",
                files={"image": img_file},
                data={"apikey": api_key, "language": "eng", "OCREngine": "2"},
                timeout=60
            )
        r.raise_for_status()
    except Exception as e:
        return f"Error: OCR request failed: {e}"
    
    try:
        result = r.json()
    except ValueError:
        return f"Response not JSON: {r.text[:200]}..."
    
    if result.get("IsErroredOnProcessing"):
        return "‚ùå OCR Failed: " + str(result.get("ErrorMessage"))
    
    parsed = result.get("ParsedResults")
    if parsed and parsed[0].get("ParsedText"):
        return parsed[0]["ParsedText"].strip()
    
    return "‚ö†Ô∏è No text found in image."

# ========== COMMUNICATION INTEGRATIONS ==========

def send_slack_message(self, query=None):
    """Send message to Slack channel"""
    if query:
        nlp = self.extract_params(query, "send_slack_message")
    else:
        nlp = {"message": "none", "channel": "none", "username": "none"}
    
    message = nlp["message"] if nlp["message"] != "none" else input("Enter Slack message: ")
    channel = nlp["channel"] if nlp["channel"] != "none" else input("Enter Slack channel: ")
    username = nlp["username"] if nlp["username"] != "none" else "AI Bot"
    
    try:
        response = requests.post(
            f"https://hooks.slack.com/services/{SLACK_TOKEN}",
            json={"text": message, "channel": f"#{channel}", "username": username}
        )
        return f"‚úÖ Slack message sent to #{channel}" if response.ok else f"‚ùå Failed: {response.text}"
    except Exception as e:
        return f"‚ùå Failed to send Slack message: {e}"

def post_tweet(self, query=None):
    """Post a tweet to Twitter/X"""
    if not TWITTER_AVAILABLE:
        return "‚ùå Tweepy not installed. Run: pip install tweepy"
    
    if query:
        nlp = self.extract_params(query, "post_tweet")
    else:
        nlp = {"tweet_text": "none", "image_path": "none"}
    
    tweet_text = nlp["tweet_text"] if nlp["tweet_text"] != "none" else input("Enter tweet text: ")
    image_path = nlp["image_path"] if nlp["image_path"] != "none" else None
    
    try:
        auth = tweepy.OAuth1UserHandler(
            TWITTER_API_KEY, TWITTER_API_SECRET,
            TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_SECRET
        )
        api = tweepy.API(auth)
        
        if image_path and os.path.exists(image_path):
            media = api.media_upload(image_path)
            api.update_status(status=tweet_text, media_ids=[media.media_id])
        else:
            api.update_status(status=tweet_text)
        
        return "‚úÖ Tweet posted successfully"
    except Exception as e:
        return f"‚ùå Failed to post tweet: {e}"

# ========== CLOUD & INFRASTRUCTURE ==========

def github_create_repo(self, query=None):
    """Create a GitHub repository"""
    if query:
        nlp = self.extract_params(query, "github_create_repo")
    else:
        nlp = {"repo_name": "none", "description": "none", "is_private": "none"}
    
    repo_name = nlp["repo_name"] if nlp["repo_name"] != "none" else input("Enter repository name: ")
    description = nlp["description"] if nlp["description"] != "none" else input("Enter description (optional): ")
    is_private = nlp["is_private"] if nlp["is_private"] != "none" else input("Private? (yes/no): ").lower() == "yes"
    
    try:
        headers = {
            "Authorization": f"token {GITHUB_TOKEN}",
            "Accept": "application/vnd.github.v3+json"
        }
        data = {
            "name": repo_name,
            "description": description,
            "private": is_private,
            "auto_init": True
        }
        response = requests.post("https://api.github.com/user/repos", headers=headers, json=data)
        if response.ok:
            repo_url = response.json().get("html_url")
            return f"‚úÖ Repository created: {repo_url}"
        return f"‚ùå Failed: {response.text}"
    except Exception as e:
        return f"‚ùå Failed to create repository: {e}"

def azure_vm_control(self, query=None):
    """Control Azure Virtual Machines"""
    if query:
        nlp = self.extract_params(query, "azure_vm_control")
    else:
        nlp = {"action": "none", "vm_name": "none", "resource_group": "none"}
    
    action = nlp["action"] if nlp["action"] != "none" else input("Action (start/stop/restart): ")
    vm_name = nlp["vm_name"] if nlp["vm_name"] != "none" else input("VM name: ")
    resource_group = nlp["resource_group"] if nlp["resource_group"] != "none" else input("Resource group: ")
    
    try:
        # Using Azure CLI via subprocess (requires az cli installed)
        cmd = f"az vm {action} --name {vm_name} --resource-group {resource_group}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            return f"‚úÖ Azure VM {vm_name} {action}ed successfully"
        else:
            return f"‚ùå Failed: {result.stderr}"
    except Exception as e:
        return f"‚ùå Failed to control Azure VM: {e}"

def dropbox_upload(self, query=None):
    """Upload file to Dropbox"""
    if not DROPBOX_AVAILABLE:
        return "‚ùå Dropbox not installed. Run: pip install dropbox"
    
    if query:
        nlp = self.extract_params(query, "dropbox_upload")
    else:
        nlp = {"local_path": "none", "remote_path": "none"}
    
    local_path = nlp["local_path"] if nlp["local_path"] != "none" else input("Local file path: ")
    remote_path = nlp["remote_path"] if nlp["remote_path"] != "none" else f"/{os.path.basename(local_path)}"
    
    try:
        dbx = dropbox.Dropbox(DROPBOX_TOKEN)
        
        with open(local_path, 'rb') as f:
            dbx.files_upload(f.read(), remote_path, mode=dropbox.files.WriteMode("overwrite"))
        
        return f"‚úÖ File uploaded to Dropbox: {remote_path}"
    except Exception as e:
        return f"‚ùå Failed to upload to Dropbox: {e}"

# ========== AI & PROCESSING ==========

def openai_chat(self, query=None):
    """Chat with OpenAI GPT"""
    if not OPENAI_AVAILABLE:
        return "‚ùå OpenAI not installed. Run: pip install openai"
    
    if query:
        nlp = self.extract_params(query, "openai_chat")
    else:
        nlp = {"prompt": "none", "model": "none", "max_tokens": "none"}
    
    prompt = nlp["prompt"] if nlp["prompt"] != "none" else input("Enter your prompt: ")
    model = nlp["model"] if nlp["model"] != "none" else "gpt-3.5-turbo"
    max_tokens = int(nlp["max_tokens"]) if nlp["max_tokens"] != "none" else 500
    
    try:
        openai.api_key = OPENAI_API_KEY
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens
        )
        return f"ü§ñ OpenAI Response:\n{response.choices[0].message.content}"
    except Exception as e:
        return f"‚ùå OpenAI request failed: {e}"

def wikipedia_search(self, query=None):
    """Search Wikipedia"""
    if not WIKIPEDIA_AVAILABLE:
        return "‚ùå Wikipedia not installed. Run: pip install wikipedia"
    
    if query:
        nlp = self.extract_params(query, "wikipedia_search")
    else:
        nlp = {"query": "none", "sentences": "none"}
    
    search_query = nlp["query"] if nlp["query"] != "none" else input("Search Wikipedia for: ")
    sentences = int(nlp["sentences"]) if nlp["sentences"] != "none" else 3
    
    try:
        result = wikipedia.summary(search_query, sentences=sentences)
        return f"üìö Wikipedia Result for '{search_query}':\n{result}"
    except Exception as e:
        return f"‚ùå Wikipedia search failed: {e}"

# ========== MEDIA & FILES ==========

def youtube_download(self, query=None):
    """Download YouTube video"""
    if not PYWHATKIT_AVAILABLE:
        return "‚ùå PyWhatKit not installed. Run: pip install pywhatkit"
    
    if query:
        nlp = self.extract_params(query, "youtube_download")
    else:
        nlp = {"url": "none", "format": "none", "output_path": "none"}
    
    url = nlp["url"] if nlp["url"] != "none" else input("YouTube URL: ")
    format_type = nlp["format"] if nlp["format"] != "none" else input("Format (mp4/mp3): ")
    output_path = nlp["output_path"] if nlp["output_path"] != "none" else "downloads/"
    
    try:
        os.makedirs(output_path, exist_ok=True)
        
        if format_type == "mp3":
            kit.download_audio(url, output_path=output_path)
            return f"‚úÖ Audio downloaded to {output_path}"
        else:
            kit.download_video(url, output_path=output_path)
            return f"‚úÖ Video downloaded to {output_path}"
    except Exception as e:
        return f"‚ùå YouTube download failed: {e}"

def qr_code_generate(self, query=None):
    """Generate QR code"""
    if query:
        nlp = self.extract_params(query, "qr_code_generate")
    else:
        nlp = {"data": "none", "filename": "none", "size": "none"}
    
    data = nlp["data"] if nlp["data"] != "none" else input("Data for QR code: ")
    filename = nlp["filename"] if nlp["filename"] != "none" else "qrcode.png"
    size = int(nlp["size"]) if nlp["size"] != "none" else 10
    
    try:
        qr = qrcode.QRCode(version=1, box_size=size, border=5)
        qr.add_data(data)
        qr.make(fit=True)
        img = qr.make_image(fill_color="black", back_color="white")
        img.save(filename)
        return f"‚úÖ QR code saved as {filename}"
    except Exception as e:
        return f"‚ùå QR code generation failed: {e}"

def screenshot(self, query=None):
    """Take screenshot"""
    if query:
        nlp = self.extract_params(query, "screenshot")
    else:
        nlp = {"filename": "none", "region": "none"}
    
    filename = nlp["filename"] if nlp["filename"] != "none" else f"screenshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
    region = nlp["region"] if nlp["region"] != "none" else None
    
    try:
        if region:
            coords = [int(x) for x in region.split(",")]
            screenshot = pyautogui.screenshot(region=coords)
        else:
            screenshot = pyautogui.screenshot()
        
        screenshot.save(filename)
        return f"‚úÖ Screenshot saved as {filename}"
    except Exception as e:
        return f"‚ùå Screenshot failed: {e}"

def video_convert(self, query=None):
    """Convert video format without pyaudio dependency"""
    if query:
        nlp = self.extract_params(query, "video_convert")
    else:
        nlp = {"input_path": "none", "output_path": "none", "format": "none"}
    
    input_path = nlp["input_path"] if nlp["input_path"] != "none" else input("Input video path: ")
    output_path = nlp["output_path"] if nlp["output_path"] != "none" else f"{os.path.splitext(input_path)[0]}_converted.mp4"
    format_type = nlp["format"] if nlp["format"] != "none" else "mp4"
    
    if not os.path.exists(input_path):
        return "‚ùå Input video not found"
    
    try:
        import subprocess
        
        # Check if ffmpeg is installed
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            return "‚ùå FFmpeg not installed. Install with: sudo apt-get install ffmpeg (Linux) or brew install ffmpeg (Mac) or download from ffmpeg.org (Windows)"
        
        # Use ffmpeg to convert video
        cmd = [
            'ffmpeg', '-i', input_path,
            '-c:v', 'libx264',  # Video codec
            '-preset', 'medium',  # Encoding preset
            '-crf', '23',  # Quality
            '-c:a', 'aac',  # Audio codec
            '-b:a', '128k',  # Audio bitrate
            '-y',  # Overwrite
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return f"‚úÖ Video converted: {output_path}"
        else:
            return f"‚ùå Video conversion failed: {result.stderr}"
            
    except Exception as e:
        return f"‚ùå Video conversion failed: {e}"

def audio_extract(self, query=None):
    """Extract audio from video without pyaudio dependency"""
    if query:
        nlp = self.extract_params(query, "audio_extract")
    else:
        nlp = {"video_path": "none", "output_path": "none"}
    
    video_path = nlp["video_path"] if nlp["video_path"] != "none" else input("Video path: ")
    output_path = nlp["output_path"] if nlp["output_path"] != "none" else f"{os.path.splitext(video_path)[0]}.mp3"
    
    if not os.path.exists(video_path):
        return "‚ùå Video file not found"
    
    try:
        # Alternative method using ffmpeg directly without moviepy
        import subprocess
        
        # Check if ffmpeg is installed
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            return "‚ùå FFmpeg not installed. Install with: sudo apt-get install ffmpeg (Linux) or brew install ffmpeg (Mac) or download from ffmpeg.org (Windows)"
        
        # Use ffmpeg to extract audio
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn',  # No video
            '-acodec', 'mp3',  # MP3 codec
            '-ab', '192k',  # Bitrate
            '-ar', '44100',  # Sample rate
            '-y',  # Overwrite output file if exists
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return f"‚úÖ Audio extracted: {output_path}"
        else:
            return f"‚ùå Audio extraction failed: {result.stderr}"
            
    except ImportError:
        return "‚ùå Required: Install ffmpeg system package\nLinux: sudo apt-get install ffmpeg\nMac: brew install ffmpeg\nWindows: Download from ffmpeg.org"
    except Exception as e:
        return f"‚ùå Audio extraction failed: {e}"

# ========== DATA & ANALYSIS ==========

def excel_operations(self, query=None):
    """Excel file operations"""
    if query:
        nlp = self.extract_params(query, "excel_operations")
    else:
        nlp = {"operation": "none", "file_path": "none", "sheet_name": "none"}
    
    operation = nlp["operation"] if nlp["operation"] != "none" else input("Operation (read/write/create): ")
    file_path = nlp["file_path"] if nlp["file_path"] != "none" else input("Excel file path: ")
    sheet_name = nlp["sheet_name"] if nlp["sheet_name"] != "none" else "Sheet1"
    
    try:
        if operation == "read":
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            return f"üìä Excel Data:\n{df.head().to_string()}"
        elif operation == "write":
            # Create sample data
            data = {"Name": ["Alice", "Bob", "Charlie"], "Score": [85, 92, 78]}
            df = pd.DataFrame(data)
            df.to_excel(file_path, sheet_name=sheet_name, index=False)
            return f"‚úÖ Excel file created: {file_path}"
        else:
            return "‚ùå Invalid operation"
    except Exception as e:
        return f"‚ùå Excel operation failed: {e}"

def database_query(self, query=None):
    """Execute database query"""
    if query:
        nlp = self.extract_params(query, "database_query")
    else:
        nlp = {"query": "none", "database_type": "none", "host": "none"}
    
    db_query = nlp["query"] if nlp["query"] != "none" else input("SQL query: ")
    db_type = nlp["database_type"] if nlp["database_type"] != "none" else input("DB type (sqlite/mysql/postgres): ")
    host = nlp["host"] if nlp["host"] != "none" else "localhost"
    
    try:
        if db_type == "sqlite":
            conn = sqlite3.connect(host)
        elif db_type == "mysql":
            conn = mysql.connector.connect(
                host=host,
                user=input("Username: "),
                password=input("Password: "),
                database=input("Database: ")
            )
        elif db_type == "postgres":
            conn = psycopg2.connect(
                host=host,
                user=input("Username: "),
                password=input("Password: "),
                database=input("Database: ")
            )
        else:
            return "‚ùå Unsupported database type"
        
        cursor = conn.cursor()
        cursor.execute(db_query)
        
        if db_query.strip().upper().startswith("SELECT"):
            results = cursor.fetchall()
            return f"üìã Query Results:\n{results}"
        else:
            conn.commit()
            return f"‚úÖ Query executed successfully"
        
        conn.close()
    except Exception as e:
        return f"‚ùå Database query failed: {e}"

def data_visualization(self, query=None):
    """Create data visualization"""
    if query:
        nlp = self.extract_params(query, "data_visualization")
    else:
        nlp = {"data_file": "none", "chart_type": "none", "output_file": "none"}
    
    data_file = nlp["data_file"] if nlp["data_file"] != "none" else input("Data file (CSV/Excel): ")
    chart_type = nlp["chart_type"] if nlp["chart_type"] != "none" else input("Chart type (line/bar/scatter): ")
    output_file = nlp["output_file"] if nlp["output_file"] != "none" else f"chart_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
    
    try:
        if data_file.endswith('.csv'):
            df = pd.read_csv(data_file)
        else:
            df = pd.read_excel(data_file)
        
        plt.figure(figsize=(10, 6))
        
        if chart_type == "line":
            plt.plot(df.iloc[:, 0], df.iloc[:, 1])
        elif chart_type == "bar":
            plt.bar(df.iloc[:, 0], df.iloc[:, 1])
        elif chart_type == "scatter":
            plt.scatter(df.iloc[:, 0], df.iloc[:, 1])
        
        plt.title(f"{chart_type.title()} Chart")
        plt.xlabel(df.columns[0])
        plt.ylabel(df.columns[1])
        plt.grid(True)
        plt.savefig(output_file)
        plt.close()
        
        return f"‚úÖ Chart saved as {output_file}"
    except Exception as e:
        return f"‚ùå Visualization failed: {e}"

def weather_info(self, query=None):
    """Get weather information"""
    if query:
        nlp = self.extract_params(query, "weather_info")
    else:
        nlp = {"city": "none", "country": "none", "units": "none"}
    
    city = nlp["city"] if nlp["city"] != "none" else input("City: ")
    country = nlp["country"] if nlp["country"] != "none" else input("Country code (e.g., US): ")
    units = nlp["units"] if nlp["units"] != "none" else "metric"
    
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q={city},{country}&appid={OPENWEATHER_API_KEY}&units={units}"
        response = requests.get(url)
        data = response.json()
        
        if response.ok:
            temp = data['main']['temp']
            desc = data['weather'][0]['description']
            humidity = data['main']['humidity']
            return f"üå§Ô∏è Weather in {city}, {country}:\nTemperature: {temp}¬∞C\nCondition: {desc}\nHumidity: {humidity}%"
        else:
            return f"‚ùå Weather data not found: {data.get('message', 'Unknown error')}"
    except Exception as e:
        return f"‚ùå Weather API failed: {e}"

def stock_price(self, query=None):
    """Get stock price information"""
    if not YFINANCE_AVAILABLE:
        return "‚ùå yfinance not installed. Run: pip install yfinance"
    
    if query:
        nlp = self.extract_params(query, "stock_price")
    else:
        nlp = {"symbol": "none", "period": "none", "interval": "none"}
    
    symbol = nlp["symbol"] if nlp["symbol"] != "none" else input("Stock symbol (e.g., AAPL): ")
    period = nlp["period"] if nlp["period"] != "none" else "1d"
    interval = nlp["interval"] if nlp["interval"] != "none" else "1m"
    
    try:
        import yfinance as yf
        stock = yf.Ticker(symbol)
        hist = stock.history(period=period, interval=interval)
        
        if not hist.empty:
            current = hist['Close'].iloc[-1]
            change = hist['Close'].iloc[-1] - hist['Close'].iloc[0]
            pct_change = (change / hist['Close'].iloc[0]) * 100
            return f"üìà {symbol} Stock:\nCurrent: ${current:.2f}\nChange: ${change:.2f} ({pct_change:.2f}%)"
        else:
            return "‚ùå No stock data found"
    except Exception as e:
        return f"‚ùå Stock data failed: {e}"

def currency_convert(self, query=None):
    """Convert currency"""
    if query:
        nlp = self.extract_params(query, "currency_convert")
    else:
        nlp = {"amount": "none", "from_currency": "none", "to_currency": "none"}
    
    amount = float(nlp["amount"]) if nlp["amount"] != "none" else float(input("Amount: "))
    from_curr = nlp["from_currency"] if nlp["from_currency"] != "none" else input("From currency (e.g., USD): ")
    to_curr = nlp["to_currency"] if nlp["to_currency"] != "none" else input("To currency (e.g., EUR): ")
    
    try:
        url = f"https://api.exchangerate-api.com/v4/latest/{from_curr}"
        response = requests.get(url)
        data = response.json()
        
        if response.ok:
            rate = data['rates'].get(to_curr)
            if rate:
                converted = amount * rate
                return f"üí± Currency Conversion:\n{amount} {from_curr} = {converted:.2f} {to_curr}\nRate: 1 {from_curr} = {rate:.4f} {to_curr}"
            else:
                return f"‚ùå Currency {to_curr} not found"
        else:
            return f"‚ùå Currency API failed: {data.get('error', 'Unknown error')}"
    except Exception as e:
        return f"‚ùå Currency conversion failed: {e}"

# ========== SECURITY & UTILITIES ==========

def encrypt_decrypt_file(self, query=None):
    """Encrypt or decrypt a file"""
    if query:
        nlp = self.extract_params(query, "encrypt_decrypt_file")
    else:
        nlp = {"operation": "none", "input_file": "none", "output_file": "none", "key": "none"}
    
    operation = nlp["operation"] if nlp["operation"] != "none" else input("Operation (encrypt/decrypt): ")
    input_file = nlp["input_file"] if nlp["input_file"] != "none" else input("Input file: ")
    output_file = nlp["output_file"] if nlp["output_file"] != "none" else input("Output file: ")
    key = nlp["key"] if nlp["key"] != "none" else Fernet.generate_key()
    
    try:
        cipher = Fernet(key)
        
        with open(input_file, 'rb') as f:
            data = f.read()
        
        if operation == "encrypt":
            encrypted = cipher.encrypt(data)
            with open(output_file, 'wb') as f:
                f.write(encrypted)
            return f"‚úÖ File encrypted: {output_file}\nKey: {key.decode()}"
        elif operation == "decrypt":
            decrypted = cipher.decrypt(data)
            with open(output_file, 'wb') as f:
                f.write(decrypted)
            return f"‚úÖ File decrypted: {output_file}"
        else:
            return "‚ùå Invalid operation"
    except Exception as e:
        return f"‚ùå Encryption/decryption failed: {e}"

def password_generate(self, query=None):
    """Generate secure password"""
    if query:
        nlp = self.extract_params(query, "password_generate")
    else:
        nlp = {"length": "none", "include_symbols": "none", "include_numbers": "none"}
    
    length = int(nlp["length"]) if nlp["length"] != "none" else 12
    include_symbols = nlp["include_symbols"] != "no" if nlp["include_symbols"] != "none" else True
    include_numbers = nlp["include_numbers"] != "no" if nlp["include_numbers"] != "none" else True
    
    try:
        chars = string.ascii_letters
        if include_numbers:
            chars += string.digits
        if include_symbols:
            chars += "!@#$%^&*()"
        
        password = ''.join(random.choice(chars) for _ in range(length))
        return f"üîê Generated Password: {password}"
    except Exception as e:
        return f"‚ùå Password generation failed: {e}"

def url_shorten(self, query=None):
    """Shorten URL using Bitly"""
    if query:
        nlp = self.extract_params(query, "url_shorten")
    else:
        nlp = {"long_url": "none", "custom_alias": "none"}
    
    long_url = nlp["long_url"] if nlp["long_url"] != "none" else input("URL to shorten: ")
    custom_alias = nlp["custom_alias"] if nlp["custom_alias"] != "none" else None
    
    try:
        headers = {
            "Authorization": f"Bearer {BITLY_TOKEN}",
            "Content-Type": "application/json"
        }
        data = {"long_url": long_url}
        if custom_alias:
            data["custom_bitlink"] = custom_alias
        
        response = requests.post("https://api-ssl.bitly.com/v4/shorten", headers=headers, json=data)
        
        if response.ok:
            short_url = response.json().get("link")
            return f"üîó Shortened URL: {short_url}"
        else:
            return f"‚ùå URL shortening failed: {response.text}"
    except Exception as e:
        return f"‚ùå URL shortening failed: {e}"

def hash_generate(self, query=None):
    """Generate hash of text"""
    if query:
        nlp = self.extract_params(query, "hash_generate")
    else:
        nlp = {"text": "none", "algorithm": "none"}
    
    text = nlp["text"] if nlp["text"] != "none" else input("Text to hash: ")
    algorithm = nlp["algorithm"] if nlp["algorithm"] != "none" else "sha256"
    
    try:
        if algorithm == "md5":
            hash_obj = hashlib.md5(text.encode())
        elif algorithm == "sha1":
            hash_obj = hashlib.sha1(text.encode())
        elif algorithm == "sha256":
            hash_obj = hashlib.sha256(text.encode())
        elif algorithm == "sha512":
            hash_obj = hashlib.sha512(text.encode())
        else:
            return "‚ùå Unsupported algorithm"
        
        hash_result = hash_obj.hexdigest()
        return f"üîí {algorithm.upper()} Hash:\n{hash_result}"
    except Exception as e:
        return f"‚ùå Hash generation failed: {e}"

# ========== SYSTEM & NETWORK ==========

def system_info(self, query=None):
    """Get system information"""
    if query:
        nlp = self.extract_params(query, "system_info")
    else:
        nlp = {"info_type": "none"}
    
    info_type = nlp["info_type"] if nlp["info_type"] != "none" else "all"
    
    try:
        info = []
        
        if info_type in ["cpu", "all"]:
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()
            info.append(f"CPU: {cpu_percent}% usage, {cpu_count} cores")
        
        if info_type in ["memory", "all"]:
            memory = psutil.virtual_memory()
            info.append(f"Memory: {memory.percent}% used ({memory.used / 1e9:.1f} GB / {memory.total / 1e9:.1f} GB)")
        
        if info_type in ["disk", "all"]:
            disk = psutil.disk_usage('/')
            info.append(f"Disk: {disk.percent}% used ({disk.used / 1e9:.1f} GB / {disk.total / 1e9:.1f} GB)")
        
        if info_type in ["network", "all"]:
            net_io = psutil.net_io_counters()
            info.append(f"Network: Sent {net_io.bytes_sent / 1e6:.1f} MB, Received {net_io.bytes_recv / 1e6:.1f} MB")
        
        return f"üíª System Info:\n" + "\n".join(info)
    except Exception as e:
        return f"‚ùå System info failed: {e}"

def process_control(self, query=None):
    """Control system processes"""
    if query:
        nlp = self.extract_params(query, "process_control")
    else:
        nlp = {"action": "none", "process_name": "none", "pid": "none"}
    
    action = nlp["action"] if nlp["action"] != "none" else input("Action (list/kill/start): ")
    process_name = nlp["process_name"] if nlp["process_name"] != "none" else None
    pid = int(nlp["pid"]) if nlp["pid"] != "none" else None
    
    try:
        if action == "list":
            processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                processes.append(f"PID: {proc.info['pid']}, Name: {proc.info['name']}, CPU: {proc.info['cpu_percent']}%, Mem: {proc.info['memory_percent']:.1f}%")
            return f"üìã Running Processes:\n" + "\n".join(processes[:10])  # Show first 10
        
        elif action == "kill":
            if pid:
                psutil.Process(pid).kill()
                return f"‚úÖ Process {pid} killed"
            elif process_name:
                for proc in psutil.process_iter():
                    if proc.name() == process_name:
                        proc.kill()
                        return f"‚úÖ Process {process_name} killed"
                return f"‚ùå Process {process_name} not found"
            else:
                return "‚ùå Need PID or process name"
        
        elif action == "start":
            if process_name:
                subprocess.Popen(process_name, shell=True)
                return f"‚úÖ Started {process_name}"
            else:
                return "‚ùå Need process name"
        
        else:
            return "‚ùå Invalid action"
    except Exception as e:
        return f"‚ùå Process control failed: {e}"

def backup_files(self, query=None):
    """Backup files/folders"""
    if query:
        nlp = self.extract_params(query, "backup_files")
    else:
        nlp = {"source": "none", "destination": "none", "compression": "none"}
    
    source = nlp["source"] if nlp["source"] != "none" else input("Source path: ")
    destination = nlp["destination"] if nlp["destination"] != "none" else input("Destination path: ")
    compression = nlp["compression"] if nlp["compression"] != "none" else "zip"
    
    try:
        if os.path.isfile(source):
            if compression == "zip":
                with zipfile.ZipFile(destination, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    zipf.write(source, os.path.basename(source))
            else:
                shutil.copy2(source, destination)
            return f"‚úÖ File backed up to {destination}"
        
        elif os.path.isdir(source):
            if compression == "zip":
                with zipfile.ZipFile(destination, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for root, dirs, files in os.walk(source):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, source)
                            zipf.write(file_path, arcname)
            else:
                shutil.copytree(source, destination)
            return f"‚úÖ Folder backed up to {destination}"
        
        else:
            return "‚ùå Source not found"
    except Exception as e:
        return f"‚ùå Backup failed: {e}"

def domain_lookup(self, query=None):
    """Look up domain information including WHOIS, DNS, and SSL certificates"""
    if query:
        nlp = self.extract_params(query, "domain_lookup")
    else:
        nlp = {"domain_name": "none", "info_type": "none"}
    
    domain_name = nlp["domain_name"] if nlp["domain_name"] != "none" else input("Enter domain name (e.g., example.com): ")
    info_type = nlp["info_type"] if nlp["info_type"] != "none" else "all"
    
    # Clean domain name
    domain_name = domain_name.strip().lower()
    if domain_name.startswith(('http://', 'https://')):
        domain_name = domain_name.split('//')[1]
    if domain_name.startswith('www.'):
        domain_name = domain_name[4:]
    
    try:
        import socket
        import ssl
        import whois
        import dns.resolver
        from datetime import datetime
        from urllib.parse import urlparse
        
        result = f"üîç Domain Information for: {domain_name}\n"
        result += "=" * 60 + "\n"
        
        # 1. Basic Domain Validation
        try:
            socket.gethostbyname(domain_name)
            result += "‚úÖ Domain is reachable\n"
        except socket.gaierror:
            result += "‚ùå Domain not found or unreachable\n"
            return result
        
        # 2. WHOIS Information
        if info_type in ["whois", "all", "registration"]:
            try:
                result += "\nüìã WHOIS Information:\n"
                result += "-" * 40 + "\n"
                
                domain_info = whois.whois(domain_name)
                
                if domain_info.domain_name:
                    result += f"üåê Domain: {domain_info.domain_name}\n"
                
                if domain_info.registrar:
                    result += f"üè¢ Registrar: {domain_info.registrar}\n"
                
                if domain_info.creation_date:
                    creation = domain_info.creation_date
                    if isinstance(creation, list):
                        creation = creation[0]
                    result += f"üìÖ Created: {creation}\n"
                    
                    # Calculate domain age
                    if isinstance(creation, datetime):
                        age_days = (datetime.now() - creation).days
                        age_years = age_days / 365.25
                        result += f"   Age: {age_days:,} days ({age_years:.1f} years)\n"
                
                if domain_info.expiration_date:
                    expiration = domain_info.expiration_date
                    if isinstance(expiration, list):
                        expiration = expiration[0]
                    result += f"üìÖ Expires: {expiration}\n"
                    
                    # Calculate days until expiration
                    if isinstance(expiration, datetime):
                        days_left = (expiration - datetime.now()).days
                        if days_left > 0:
                            result += f"   Expires in: {days_left} days\n"
                        else:
                            result += f"   ‚ö†Ô∏è Expired {abs(days_left)} days ago\n"
                
                if domain_info.updated_date:
                    updated = domain_info.updated_date
                    if isinstance(updated, list):
                        updated = updated[0]
                    result += f"üîÑ Last Updated: {updated}\n"
                
                if domain_info.name_servers:
                    servers = domain_info.name_servers
                    if isinstance(servers, list):
                        result += f"üîß Name Servers: {', '.join(servers[:3])}\n"
                        if len(servers) > 3:
                            result += f"   ... and {len(servers)-3} more\n"
                    else:
                        result += f"üîß Name Servers: {servers}\n"
                
                if domain_info.status:
                    status = domain_info.status
                    if isinstance(status, list):
                        result += f"üìä Status: {', '.join(status)}\n"
                    else:
                        result += f"üìä Status: {status}\n"
                        
            except Exception as e:
                result += f"‚ùå WHOIS lookup failed: {str(e)[:100]}\n"
        
        # 3. DNS Records
        if info_type in ["dns", "all", "records"]:
            try:
                result += "\nüåê DNS Records:\n"
                result += "-" * 40 + "\n"
                
                # A Records (IPv4)
                try:
                    a_records = dns.resolver.resolve(domain_name, 'A')
                    if a_records:
                        result += f"üìç A Records (IPv4):\n"
                        for rdata in a_records:
                            result += f"   ‚Ä¢ {rdata.address}\n"
                except:
                    result += "üìç No A records found\n"
                
                # AAAA Records (IPv6)
                try:
                    aaaa_records = dns.resolver.resolve(domain_name, 'AAAA')
                    if aaaa_records:
                        result += f"üìç AAAA Records (IPv6):\n"
                        for rdata in aaaa_records:
                            result += f"   ‚Ä¢ {rdata.address}\n"
                except:
                    pass  # IPv6 records are optional
                
                # MX Records (Mail Servers)
                try:
                    mx_records = dns.resolver.resolve(domain_name, 'MX')
                    if mx_records:
                        result += f"üìß MX Records (Mail):\n"
                        for rdata in mx_records:
                            result += f"   ‚Ä¢ {rdata.exchange} (Priority: {rdata.preference})\n"
                except:
                    result += "üìß No MX records found\n"
                
                # NS Records (Name Servers)
                try:
                    ns_records = dns.resolver.resolve(domain_name, 'NS')
                    if ns_records:
                        result += f"üîß NS Records:\n"
                        for rdata in ns_records:
                            result += f"   ‚Ä¢ {rdata.target}\n"
                except:
                    pass
                
                # TXT Records
                try:
                    txt_records = dns.resolver.resolve(domain_name, 'TXT')
                    if txt_records:
                        result += f"üìù TXT Records:\n"
                        for rdata in txt_records:
                            for txt_string in rdata.strings:
                                txt_str = txt_string.decode('utf-8', errors='ignore')
                                if len(txt_str) > 50:
                                    txt_str = txt_str[:47] + "..."
                                result += f"   ‚Ä¢ {txt_str}\n"
                except:
                    pass
                
                # CNAME Records
                try:
                    cname_records = dns.resolver.resolve(domain_name, 'CNAME')
                    if cname_records:
                        result += f"üîó CNAME Records:\n"
                        for rdata in cname_records:
                            result += f"   ‚Ä¢ {rdata.target}\n"
                except:
                    pass
                    
            except Exception as e:
                result += f"‚ùå DNS lookup failed: {str(e)[:100]}\n"
        
        # 4. SSL Certificate Information
        if info_type in ["ssl", "all", "security"]:
            try:
                result += "\nüîê SSL Certificate:\n"
                result += "-" * 40 + "\n"
                
                context = ssl.create_default_context()
                with socket.create_connection((domain_name, 443), timeout=5) as sock:
                    with context.wrap_socket(sock, server_hostname=domain_name) as ssock:
                        cert = ssock.getpeercert()
                        
                        # Issuer
                        issuer = dict(x[0] for x in cert['issuer'])
                        result += f"üèõÔ∏è Issuer: {issuer.get('organizationName', 'Unknown')}\n"
                        
                        # Validity Period
                        not_before = datetime.strptime(cert['notBefore'], '%b %d %H:%M:%S %Y %Z')
                        not_after = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                        
                        result += f"üìÖ Valid From: {not_before}\n"
                        result += f"üìÖ Valid Until: {not_after}\n"
                        
                        # Days remaining
                        days_left = (not_after - datetime.now()).days
                        if days_left > 30:
                            result += f"   ‚è≥ Expires in: {days_left} days\n"
                        elif days_left > 0:
                            result += f"   ‚ö†Ô∏è Expires soon: {days_left} days\n"
                        else:
                            result += f"   ‚ùå EXPIRED: {abs(days_left)} days ago\n"
                        
                        # Subject
                        subject = dict(x[0] for x in cert['subject'])
                        result += f"üìù Subject: {subject.get('commonName', 'Unknown')}\n"
                        
                        # SAN (Subject Alternative Names)
                        if 'subjectAltName' in cert:
                            sans = cert['subjectAltName']
                            result += f"üåê Alternative Names:\n"
                            for san_type, san_name in sans[:3]:  # Show first 3
                                result += f"   ‚Ä¢ {san_name}\n"
                            if len(sans) > 3:
                                result += f"   ... and {len(sans)-3} more\n"
                        
                        # Signature algorithm
                        result += f"üîè Signature Algorithm: {cert.get('signatureAlgorithm', 'Unknown')}\n"
                        
            except Exception as e:
                result += f"‚ùå SSL check failed: {str(e)[:100]}\n"
                result += f"   (Domain may not support HTTPS or certificate invalid)\n"
        
        # 5. HTTP/HTTPS Information
        if info_type in ["http", "all", "web"]:
            try:
                result += "\nüåê Web Server Information:\n"
                result += "-" * 40 + "\n"
                
                # Check HTTP
                try:
                    http_url = f"http://{domain_name}"
                    http_response = requests.get(http_url, timeout=5, allow_redirects=True)
                    result += f"üîó HTTP: {http_response.status_code} {http_response.reason}\n"
                    if 'Server' in http_response.headers:
                        result += f"   Server: {http_response.headers['Server']}\n"
                except:
                    result += "üîó HTTP: Connection failed\n"
                
                # Check HTTPS
                try:
                    https_url = f"https://{domain_name}"
                    https_response = requests.get(https_url, timeout=5, allow_redirects=True)
                    result += f"üîê HTTPS: {https_response.status_code} {https_response.reason}\n"
                    if 'Server' in https_response.headers:
                        result += f"   Server: {https_response.headers['Server']}\n"
                    
                    # Check redirects
                    if len(https_response.history) > 0:
                        result += f"   ‚Ü™Ô∏è Redirects: {len(https_response.history)}\n"
                        for i, resp in enumerate(https_response.history):
                            result += f"      {i+1}. {resp.status_code} ‚Üí {resp.url}\n"
                    
                except:
                    result += "üîê HTTPS: Connection failed\n"
                
            except Exception as e:
                result += f"‚ùå HTTP check failed: {str(e)[:100]}\n"
        
        # 6. IP Information
        if info_type in ["ip", "all", "network"]:
            try:
                result += "\nüì° Network Information:\n"
                result += "-" * 40 + "\n"
                
                # Get IP addresses
                ipv4_addresses = []
                ipv6_addresses = []
                
                try:
                    addr_info = socket.getaddrinfo(domain_name, None)
                    for addr in addr_info:
                        ip = addr[4][0]
                        if ':' in ip:  # IPv6
                            if ip not in ipv6_addresses:
                                ipv6_addresses.append(ip)
                        else:  # IPv4
                            if ip not in ipv4_addresses:
                                ipv4_addresses.append(ip)
                except:
                    pass
                
                if ipv4_addresses:
                    result += f"üìç IPv4 Addresses:\n"
                    for ip in ipv4_addresses[:3]:  # Show first 3
                        result += f"   ‚Ä¢ {ip}\n"
                    if len(ipv4_addresses) > 3:
                        result += f"   ... and {len(ipv4_addresses)-3} more\n"
                
                if ipv6_addresses:
                    result += f"üìç IPv6 Addresses:\n"
                    for ip in ipv6_addresses[:2]:  # Show first 2
                        result += f"   ‚Ä¢ {ip}\n"
                
                # Get hostname from IP (reverse lookup)
                if ipv4_addresses:
                    try:
                        hostname, aliaslist, ipaddrlist = socket.gethostbyaddr(ipv4_addresses[0])
                        result += f"üè∑Ô∏è Reverse DNS: {hostname}\n"
                    except:
                        pass
                        
            except Exception as e:
                result += f"‚ùå Network check failed: {str(e)[:100]}\n"
        
        # 7. Domain Reputation Check (Simple)
        if info_type in ["reputation", "all", "security"]:
            try:
                result += "\nüõ°Ô∏è Security Check:\n"
                result += "-" * 40 + "\n"
                
                # Check for common phishing patterns
                suspicious_keywords = ['login', 'account', 'secure', 'verify', 'bank', 'paypal']
                keyword_count = sum(1 for keyword in suspicious_keywords if keyword in domain_name)
                if keyword_count > 2:
                    result += "‚ö†Ô∏è Warning: Domain contains suspicious keywords\n"
                
                # Check domain length (very long domains can be suspicious)
                if len(domain_name) > 30:
                    result += "‚ö†Ô∏è Warning: Unusually long domain name\n"
                
                # Check for hyphens (can indicate spoofing)
                if domain_name.count('-') > 2:
                    result += "‚ö†Ô∏è Warning: Multiple hyphens in domain\n"
                
                # Check if it's a popular TLD
                popular_tlds = ['.com', '.org', '.net', '.edu', '.gov']
                domain_tld = '.' + domain_name.split('.')[-1]
                if domain_tld not in popular_tlds:
                    result += f"‚ÑπÔ∏è  Uses {domain_tld} TLD (less common)\n"
                else:
                    result += f"‚úÖ Uses {domain_tld} TLD (common and trusted)\n"
                
                # Check age if we have it
                if 'Age:' in result:
                    if 'years' in result:
                        # Extract age from earlier result
                        import re
                        age_match = re.search(r'Age:.*?([\d.]+) years', result)
                        if age_match:
                            age = float(age_match.group(1))
                            if age < 1:
                                result += "‚ö†Ô∏è Warning: Domain is less than 1 year old\n"
                            elif age > 5:
                                result += "‚úÖ Domain is well-established\n"
                
            except:
                pass
        
        result += "\n" + "=" * 60 + "\n"
        result += "üí° Tip: Use 'whois', 'dns', 'ssl', 'http', 'ip', or 'reputation' for specific info\n"
        
        return result
        
    except ImportError as e:
        missing_lib = str(e).split("'")[1] if "'" in str(e) else str(e)
        if missing_lib == 'whois':
            return "‚ùå WHOIS library not installed. Run: pip install python-whois"
        elif missing_lib == 'dns':
            return "‚ùå DNS library not installed. Run: pip install dnspython"
        else:
            return f"‚ùå Missing library: {missing_lib}\nInstall: pip install python-whois dnspython"
    except Exception as e:
        return f"‚ùå Domain lookup failed: {e}"

def api_test(self, query=None):
    """Test API endpoints with various HTTP methods"""
    if query:
        nlp = self.extract_params(query, "api_test")
    else:
        nlp = {"url": "none", "method": "none", "payload": "none", "headers": "none"}
    
    url = nlp["url"] if nlp["url"] != "none" else input("Enter API URL: ")
    method = nlp["method"] if nlp["method"] != "none" else input("HTTP method (GET/POST/PUT/DELETE/PATCH): ").upper()
    payload = nlp["payload"] if nlp["payload"] != "none" else None
    headers = nlp["headers"] if nlp["headers"] != "none" else None
    
    # Validate URL
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    try:
        result = f"üîß API Test Results\n"
        result += "=" * 60 + "\n"
        result += f"üåê URL: {url}\n"
        result += f"üì° Method: {method}\n"
        
        # Parse headers if provided as string
        headers_dict = {}
        if headers:
            if isinstance(headers, str):
                try:
                    # Try to parse as JSON
                    import json
                    headers_dict = json.loads(headers)
                except:
                    # Parse as key:value pairs
                    for line in headers.split(','):
                        if ':' in line:
                            key, value = line.split(':', 1)
                            headers_dict[key.strip()] = value.strip()
            elif isinstance(headers, dict):
                headers_dict = headers
        
        # Parse payload if provided as string
        payload_data = None
        if payload:
            if isinstance(payload, str):
                try:
                    # Try to parse as JSON
                    import json
                    payload_data = json.loads(payload)
                    content_type = 'application/json'
                except:
                    # Treat as form data
                    payload_data = payload
                    content_type = 'application/x-www-form-urlencoded'
            else:
                payload_data = payload
                content_type = 'application/json'
        
        # Set default headers if not provided
        if not headers_dict:
            headers_dict = {
                'User-Agent': 'Optimind-API-Tester/1.0',
                'Accept': 'application/json',
            }
            if payload_data and content_type == 'application/json':
                headers_dict['Content-Type'] = 'application/json'
        
        result += f"üìã Headers: {json.dumps(headers_dict, indent=2)}\n"
        
        if payload_data:
            result += f"üì¶ Payload: {json.dumps(payload_data, indent=2) if content_type == 'application/json' else payload_data}\n"
        
        result += "-" * 60 + "\n"
        
        # Time the request
        import time
        start_time = time.time()
        
        # Make the API request
        if method == 'GET':
            response = requests.get(url, headers=headers_dict, params=payload_data if isinstance(payload_data, dict) else None, timeout=10)
        elif method == 'POST':
            response = requests.post(url, headers=headers_dict, 
                                    json=payload_data if content_type == 'application/json' else None,
                                    data=payload_data if content_type != 'application/json' else None,
                                    timeout=10)
        elif method == 'PUT':
            response = requests.put(url, headers=headers_dict, 
                                   json=payload_data if content_type == 'application/json' else None,
                                   data=payload_data if content_type != 'application/json' else None,
                                   timeout=10)
        elif method == 'DELETE':
            response = requests.delete(url, headers=headers_dict, timeout=10)
        elif method == 'PATCH':
            response = requests.patch(url, headers=headers_dict, 
                                     json=payload_data if content_type == 'application/json' else None,
                                     data=payload_data if content_type != 'application/json' else None,
                                     timeout=10)
        elif method == 'HEAD':
            response = requests.head(url, headers=headers_dict, timeout=10)
        elif method == 'OPTIONS':
            response = requests.options(url, headers=headers_dict, timeout=10)
        else:
            return f"‚ùå Unsupported HTTP method: {method}"
        
        end_time = time.time()
        response_time = (end_time - start_time) * 1000  # Convert to milliseconds
        
        # Response details
        result += f"‚è±Ô∏è  Response Time: {response_time:.2f} ms\n"
        result += f"üìä Status Code: {response.status_code} {response.reason}\n"
        
        # Color code status
        if 200 <= response.status_code < 300:
            status_emoji = "‚úÖ"
        elif 300 <= response.status_code < 400:
            status_emoji = "üîÑ"
        elif 400 <= response.status_code < 500:
            status_emoji = "‚ö†Ô∏è"
        else:
            status_emoji = "‚ùå"
        
        result += f"üìà Status: {status_emoji} {self._get_status_description(response.status_code)}\n"
        
        # Response headers
        result += "\nüìã Response Headers:\n"
        result += "-" * 40 + "\n"
        for key, value in response.headers.items():
            result += f"  {key}: {value}\n"
        
        # Response body
        result += "\nüìÑ Response Body:\n"
        result += "-" * 40 + "\n"
        
        try:
            # Try to parse as JSON
            response_json = response.json()
            result += json.dumps(response_json, indent=2)
            
            # Add JSON size info
            result += f"\n\nüìè JSON Size: {len(response.text)} characters"
            
            # Check for common API response patterns
            if isinstance(response_json, dict):
                if 'error' in response_json:
                    result += f"\n‚ö†Ô∏è  Error in response: {response_json.get('error')}"
                if 'message' in response_json:
                    result += f"\nüí¨ Message: {response_json.get('message')}"
                if 'data' in response_json:
                    data_size = len(str(response_json['data']))
                    result += f"\nüìä Data payload: {data_size} characters"
                    
        except ValueError:
            # Not JSON, show as text
            if response.text:
                result += response.text[:1000]  # Limit to 1000 chars
                if len(response.text) > 1000:
                    result += f"\n... (truncated, showing first 1000 of {len(response.text)} characters)"
            else:
                result += "[Empty response body]"
        
        # Performance metrics
        result += "\n\nüìä Performance Metrics:\n"
        result += "-" * 40 + "\n"
        result += f"‚è±Ô∏è  Total Time: {response_time:.2f} ms\n"
        result += f"üì¶ Response Size: {len(response.content)} bytes\n"
        result += f"üîó URL Length: {len(url)} characters\n"
        
        # SSL/TLS info for HTTPS URLs
        if url.startswith('https://'):
            try:
                import ssl
                import socket
                from urllib.parse import urlparse
                
                parsed_url = urlparse(url)
                hostname = parsed_url.hostname
                
                context = ssl.create_default_context()
                with socket.create_connection((hostname, 443), timeout=5) as sock:
                    with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                        cert = ssock.getpeercert()
                        result += f"üîê SSL: Certificate verified\n"
                        
            except:
                result += f"üîê SSL: Certificate verification failed\n"
        
        # Save to history
        self._save_api_test_history(url, method, response.status_code, response_time)
        
        # Show history summary
        history = self._get_api_test_history()
        if history:
            result += "\n\nüìú Recent Tests:\n"
            result += "-" * 40 + "\n"
            for i, test in enumerate(history[-3:]):  # Last 3 tests
                result += f"{i+1}. {test['method']} {test['url']} - {test['status']} ({test['time']:.0f}ms)\n"
        
        return result
        
    except requests.exceptions.Timeout:
        return f"‚ùå Request timeout after 10 seconds"
    except requests.exceptions.ConnectionError:
        return f"‚ùå Connection failed. Check URL and network connection"
    except requests.exceptions.TooManyRedirects:
        return f"‚ùå Too many redirects"
    except requests.exceptions.RequestException as e:
        return f"‚ùå Request failed: {e}"
    except Exception as e:
        return f"‚ùå API test failed: {e}"

def _get_status_description(self, status_code):
    """Get description for HTTP status codes"""
    status_descriptions = {
        100: "Continue",
        101: "Switching Protocols",
        200: "OK",
        201: "Created",
        202: "Accepted",
        204: "No Content",
        301: "Moved Permanently",
        302: "Found",
        304: "Not Modified",
        400: "Bad Request",
        401: "Unauthorized",
        403: "Forbidden",
        404: "Not Found",
        405: "Method Not Allowed",
        409: "Conflict",
        422: "Unprocessable Entity",
        429: "Too Many Requests",
        500: "Internal Server Error",
        502: "Bad Gateway",
        503: "Service Unavailable",
        504: "Gateway Timeout"
    }
    return status_descriptions.get(status_code, "Unknown Status")

def _save_api_test_history(self, url, method, status, response_time):
    """Save API test to history"""
    try:
        import json
        from datetime import datetime
        
        test_record = {
            'timestamp': datetime.now().isoformat(),
            'url': url,
            'method': method,
            'status': status,
            'time': response_time
        }
        
        # Load existing history
        history_file = 'api_test_history.json'
        history = []
        if os.path.exists(history_file):
            with open(history_file, 'r') as f:
                history = json.load(f)
        
        # Add new record
        history.append(test_record)
        
        # Keep only last 50 records
        if len(history) > 50:
            history = history[-50:]
        
        # Save back
        with open(history_file, 'w') as f:
            json.dump(history, f, indent=2)
            
    except:
        pass  # Silently fail if history can't be saved

def _get_api_test_history(self):
    """Get API test history"""
    try:
        import json
        history_file = 'api_test_history.json'
        if os.path.exists(history_file):
            with open(history_file, 'r') as f:
                return json.load(f)
    except:
        pass
    return []

# Advanced testing functions
def api_load_test(self, query=None):
    """Perform load testing on API endpoints"""
    if query:
        nlp = self.extract_params(query, "load_test")
    else:
        nlp = {"url": "none", "users": "none", "duration": "none"}
    
    url = nlp["url"] if nlp["url"] != "none" else input("Enter API URL: ")
    users = int(nlp["users"]) if nlp["users"] != "none" else int(input("Number of concurrent users: "))
    duration = int(nlp["duration"]) if nlp["duration"] != "none" else int(input("Test duration (seconds): "))
    
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    try:
        import threading
        import time
        from collections import defaultdict
        
        result = f"üöÄ API Load Test\n"
        result += "=" * 60 + "\n"
        result += f"üåê URL: {url}\n"
        result += f"üë• Concurrent Users: {users}\n"
        result += f"‚è±Ô∏è  Duration: {duration} seconds\n"
        result += "-" * 60 + "\n"
        
        stats = defaultdict(int)
        errors = []
        start_time = time.time()
        
        def make_request(thread_id):
            nonlocal stats, errors
            end_time = start_time + duration
            
            while time.time() < end_time:
                try:
                    request_start = time.time()
                    response = requests.get(url, timeout=5)
                    request_time = (time.time() - request_start) * 1000
                    
                    stats['total_requests'] += 1
                    stats['total_time'] += request_time
                    
                    status_code = response.status_code
                    if 200 <= status_code < 300:
                        stats['success'] += 1
                    elif 400 <= status_code < 500:
                        stats['client_errors'] += 1
                    elif 500 <= status_code < 600:
                        stats['server_errors'] += 1
                    
                    if request_time > 1000:  # Slow requests
                        stats['slow_requests'] += 1
                        
                except Exception as e:
                    stats['errors'] += 1
                    errors.append(str(e))
        
        # Create and start threads
        threads = []
        for i in range(users):
            thread = threading.Thread(target=make_request, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Show progress
        for remaining in range(duration, 0, -1):
            time.sleep(1)
            print(f"‚è≥ Testing... {remaining}s remaining", end='\r')
        
        print("\n‚úÖ Test complete!")
        
        # Wait for all threads to finish
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        
        # Calculate statistics
        result += "\nüìä Load Test Results:\n"
        result += "-" * 40 + "\n"
        result += f"‚è±Ô∏è  Total Time: {total_time:.2f}s\n"
        result += f"üìà Total Requests: {stats['total_requests']}\n"
        result += f"üìä Requests/Second: {stats['total_requests']/total_time:.2f}\n"
        result += f"‚úÖ Successful: {stats['success']}\n"
        result += f"‚ö†Ô∏è  Client Errors: {stats['client_errors']}\n"
        result += f"‚ùå Server Errors: {stats['server_errors']}\n"
        result += f"üêå Slow Requests (>1s): {stats.get('slow_requests', 0)}\n"
        result += f"üí• Total Errors: {stats.get('errors', 0)}\n"
        
        if stats['total_requests'] > 0:
            avg_time = stats['total_time'] / stats['total_requests']
            result += f"‚ö° Average Response Time: {avg_time:.2f}ms\n"
            success_rate = (stats['success'] / stats['total_requests']) * 100
            result += f"üìä Success Rate: {success_rate:.1f}%\n"
        
        if errors:
            result += f"\nüí• Error Samples (first 5):\n"
            for error in errors[:5]:
                result += f"  ‚Ä¢ {error}\n"
        
        return result
        
    except Exception as e:
        return f"‚ùå Load test failed: {e}"

def log_analyze(self, query=None):
    """Analyze log files for patterns, errors, and insights"""
    if query:
        nlp = self.extract_params(query, "log_analyze")
    else:
        nlp = {"log_file": "none", "pattern": "none", "output": "none", "time_range": "none"}
    
    log_file = nlp["log_file"] if nlp["log_file"] != "none" else input("Enter log file path: ")
    pattern = nlp["pattern"] if nlp["pattern"] != "none" else None
    output = nlp["output"] if nlp["output"] != "none" else None
    time_range = nlp["time_range"] if nlp["time_range"] != "none" else "all"
    
    try:
        # Check if file exists
        if not os.path.exists(log_file):
            return f"‚ùå Log file not found: {log_file}"
        
        file_size = os.path.getsize(log_file)
        if file_size > 100 * 1024 * 1024:  # 100MB limit
            return f"‚ùå File too large ({file_size/1024/1024:.1f} MB). Use smaller log file."
        
        result = f"üìä Log Analysis: {os.path.basename(log_file)}\n"
        result += "=" * 70 + "\n"
        result += f"üìÅ File: {log_file}\n"
        result += f"üìè Size: {file_size:,} bytes ({file_size/1024:.1f} KB)\n"
        
        # Read log file
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        total_lines = len(lines)
        result += f"üìà Total Lines: {total_lines:,}\n"
        
        if total_lines == 0:
            return result + "‚ùå Log file is empty"
        
        # Parse timestamps and analyze structure
        timestamps = []
        log_levels = {'ERROR': 0, 'WARN': 0, 'WARNING': 0, 'INFO': 0, 'DEBUG': 0, 'FATAL': 0, 'CRITICAL': 0}
        ip_addresses = {}
        urls = {}
        users = {}
        error_messages = {}
        
        # Common patterns
        import re
        
        # Timestamp patterns
        timestamp_patterns = [
            r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}',  # 2024-01-01 12:00:00
            r'\d{2}/\d{2}/\d{4} \d{2}:\d{2}:\d{2}',  # 01/01/2024 12:00:00
            r'\d{2}-[A-Za-z]{3}-\d{4} \d{2}:\d{2}:\d{2}',  # 01-Jan-2024 12:00:00
            r'\d{10,13}',  # Unix timestamp
        ]
        
        # IP address pattern
        ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
        
        # URL pattern
        url_pattern = r'(https?://[^\s]+|www\.[^\s]+)'
        
        # User/ID pattern
        user_pattern = r'user[:_-]?[=:]?\s*([^\s,]+)|\buser_id[=:]?\s*(\d+)|\busername[=:]?\s*([^\s,]+)'
        
        # Error pattern
        error_pattern = r'(error|exception|fail|fatal|critical|panic|timeout|denied|forbidden|unauthorized)'
        
        for i, line in enumerate(lines, 1):
            line = line.strip()
            if not line:
                continue
            
            # Extract timestamp
            timestamp = None
            for pattern in timestamp_patterns:
                match = re.search(pattern, line)
                if match:
                    timestamp = match.group()
                    timestamps.append(timestamp)
                    break
            
            # Count log levels
            line_upper = line.upper()
            for level in log_levels.keys():
                if level in line_upper:
                    log_levels[level] += 1
                    if level in ['ERROR', 'FATAL', 'CRITICAL']:
                        # Extract error message
                        error_key = line[:100]  # Use first 100 chars as key
                        error_messages[error_key] = error_messages.get(error_key, 0) + 1
                    break
            
            # Extract IP addresses
            ips = re.findall(ip_pattern, line)
            for ip in ips:
                ip_addresses[ip] = ip_addresses.get(ip, 0) + 1
            
            # Extract URLs
            urls_found = re.findall(url_pattern, line)
            for url in urls_found:
                urls[url] = urls.get(url, 0) + 1
            
            # Extract users
            users_found = re.findall(user_pattern, line, re.IGNORECASE)
            for match in users_found:
                for user in match:
                    if user:
                        users[user] = users.get(user, 0) + 1
                        break
        
        # Calculate statistics
        result += "\nüìà Log Level Distribution:\n"
        result += "-" * 40 + "\n"
        total_logs = sum(log_levels.values())
        for level, count in sorted(log_levels.items(), key=lambda x: x[1], reverse=True):
            if count > 0:
                percentage = (count / total_lines) * 100 if total_lines > 0 else 0
                result += f"{self._get_log_level_emoji(level)} {level:<10} {count:>6,} ({percentage:.1f}%)\n"
        
        # Time-based analysis
        if timestamps:
            result += "\n‚è±Ô∏è  Time Analysis:\n"
            result += "-" * 40 + "\n"
            result += f"üìÖ Time Range: {timestamps[0]} to {timestamps[-1]}\n"
            
            # Calculate logs per hour (simplified)
            if len(timestamps) > 100:
                hour_counts = {}
                for ts in timestamps:
                    try:
                        hour = ts.split(':')[0][-2:]  # Extract hour
                        hour_counts[hour] = hour_counts.get(hour, 0) + 1
                    except:
                        pass
                
                if hour_counts:
                    busiest_hour = max(hour_counts.items(), key=lambda x: x[1])
                    result += f"üìä Busiest Hour: {busiest_hour[0]}:00 ({busiest_hour[1]:,} logs)\n"
        
        # Error Analysis
        error_count = log_levels['ERROR'] + log_levels['FATAL'] + log_levels['CRITICAL']
        if error_count > 0:
            result += "\n‚ùå Error Analysis:\n"
            result += "-" * 40 + "\n"
            result += f"Total Errors: {error_count:,}\n"
            result += f"Error Rate: {(error_count/total_lines)*100:.2f}%\n"
            
            # Show top error messages
            if error_messages:
                result += "\nüîç Top Error Messages:\n"
                for error_msg, count in sorted(error_messages.items(), key=lambda x: x[1], reverse=True)[:5]:
                    result += f"  ‚Ä¢ {count}x: {error_msg[:80]}...\n"
        
        # IP Analysis
        if ip_addresses:
            result += "\nüåê IP Address Analysis:\n"
            result += "-" * 40 + "\n"
            result += f"Unique IPs: {len(ip_addresses):,}\n"
            
            top_ips = sorted(ip_addresses.items(), key=lambda x: x[1], reverse=True)[:5]
            result += "üìä Top IP Addresses:\n"
            for ip, count in top_ips:
                percentage = (count / total_lines) * 100
                result += f"  ‚Ä¢ {ip:<15} {count:>6,} ({percentage:.1f}%)\n"
        
        # URL Analysis
        if urls:
            result += "\nüîó URL Analysis:\n"
            result += "-" * 40 + "\n"
            result += f"Unique URLs: {len(urls):,}\n"
            
            top_urls = sorted(urls.items(), key=lambda x: x[1], reverse=True)[:3]
            result += "üìä Most Accessed URLs:\n"
            for url, count in top_urls:
                if len(url) > 50:
                    url_display = url[:47] + "..."
                else:
                    url_display = url
                result += f"  ‚Ä¢ {url_display:<50} {count:,}\n"
        
        # User Analysis
        if users:
            result += "\nüë§ User Activity:\n"
            result += "-" * 40 + "\n"
            result += f"Unique Users/IDs: {len(users):,}\n"
            
            top_users = sorted(users.items(), key=lambda x: x[1], reverse=True)[:5]
            result += "üìä Most Active Users:\n"
            for user, count in top_users:
                result += f"  ‚Ä¢ {user:<20} {count:>6,}\n"
        
        # Pattern Search
        if pattern:
            result += f"\nüîç Pattern Search: '{pattern}'\n"
            result += "-" * 40 + "\n"
            
            pattern_matches = []
            for line in lines:
                if re.search(pattern, line, re.IGNORECASE):
                    pattern_matches.append(line.strip())
            
            result += f"Matches Found: {len(pattern_matches):,}\n"
            if pattern_matches:
                result += "üìÑ Sample Matches:\n"
                for match in pattern_matches[:3]:
                    if len(match) > 100:
                        match = match[:97] + "..."
                    result += f"  ‚Ä¢ {match}\n"
        
        # Line-by-line analysis for specific patterns
        result += "\nüî¨ Detailed Analysis:\n"
        result += "-" * 40 + "\n"
        
        # Find long response times
        response_times = []
        for line in lines:
            time_match = re.search(r'(\d+\.?\d*)\s*(ms|s|seconds?|milliseconds?)', line, re.IGNORECASE)
            if time_match:
                try:
                    value = float(time_match.group(1))
                    unit = time_match.group(2).lower()
                    if unit.startswith('s'):  # Convert seconds to milliseconds
                        value *= 1000
                    response_times.append(value)
                except:
                    pass
        
        if response_times:
            avg_time = sum(response_times) / len(response_times)
            max_time = max(response_times)
            slow_count = len([t for t in response_times if t > 1000])  # > 1 second
            
            result += f"‚è±Ô∏è  Response Times: {len(response_times):,} measurements\n"
            result += f"  Average: {avg_time:.0f} ms\n"
            result += f"  Maximum: {max_time:.0f} ms\n"
            result += f"  Slow (>1s): {slow_count:,}\n"
        
        # Find status codes
        status_codes = {}
        for line in lines:
            status_match = re.search(r'\b(\d{3})\b', line)
            if status_match:
                code = status_match.group(1)
                if code.startswith(('2', '3', '4', '5')):
                    status_codes[code] = status_codes.get(code, 0) + 1
        
        if status_codes:
            result += f"\nüìä HTTP Status Codes:\n"
            for code, count in sorted(status_codes.items()):
                emoji = self._get_status_emoji(code)
                result += f"  {emoji} {code}: {count:,}\n"
        
        # Memory/CPU usage patterns
        memory_usage = []
        cpu_usage = []
        for line in lines:
            # Look for memory usage
            mem_match = re.search(r'(\d+\.?\d*)\s*(MB|GB|KB|%)?\s*(memory|ram|heap)', line, re.IGNORECASE)
            if mem_match:
                try:
                    value = float(mem_match.group(1))
                    memory_usage.append(value)
                except:
                    pass
            
            # Look for CPU usage
            cpu_match = re.search(r'(\d+\.?\d*)\s*%?\s*(cpu|load)', line, re.IGNORECASE)
            if cpu_match:
                try:
                    value = float(cpu_match.group(1))
                    cpu_usage.append(value)
                except:
                    pass
        
        if memory_usage:
            avg_mem = sum(memory_usage) / len(memory_usage)
            max_mem = max(memory_usage)
            result += f"\nüíæ Memory Usage: {len(memory_usage):,} samples\n"
            result += f"  Average: {avg_mem:.1f}\n"
            result += f"  Maximum: {max_mem:.1f}\n"
        
        if cpu_usage:
            avg_cpu = sum(cpu_usage) / len(cpu_usage)
            max_cpu = max(cpu_usage)
            result += f"\n‚ö° CPU Usage: {len(cpu_usage):,} samples\n"
            result += f"  Average: {avg_cpu:.1f}%\n"
            result += f"  Maximum: {max_cpu:.1f}%\n"
        
        # Summary
        result += "\nüìã Summary:\n"
        result += "-" * 40 + "\n"
        
        if error_count > total_lines * 0.1:  # More than 10% errors
            result += "üî¥ CRITICAL: High error rate detected!\n"
        elif error_count > total_lines * 0.05:  # More than 5% errors
            result += "üü† WARNING: Elevated error rate\n"
        else:
            result += "üü¢ HEALTHY: Normal error rate\n"
        
        if len(ip_addresses) > 1000:
            result += "üåê HIGH TRAFFIC: Many unique IP addresses\n"
        
        if len(urls) > 500:
            result += "üîó ACTIVE: Many URLs accessed\n"
        
        # Save analysis to file if requested
        if output:
            with open(output, 'w', encoding='utf-8') as f:
                f.write(result)
            result += f"\nüíæ Analysis saved to: {output}\n"
        
        # Generate recommendations
        result += "\nüí° Recommendations:\n"
        result += "-" * 40 + "\n"
        
        recommendations = []
        if error_count > 0:
            recommendations.append("Investigate top error messages")
        if len(ip_addresses) > 100:
            recommendations.append("Monitor for suspicious IP addresses")
        if response_times and avg_time > 500:
            recommendations.append("Optimize slow endpoints")
        if memory_usage and max_mem > 2048:  # > 2GB
            recommendations.append("Check for memory leaks")
        
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                result += f"{i}. {rec}\n"
        else:
            result += "No urgent issues detected\n"
        
        return result
        
    except Exception as e:
        return f"‚ùå Log analysis failed: {e}"

def _get_log_level_emoji(self, level):
    """Get emoji for log level"""
    emoji_map = {
        'ERROR': '‚ùå',
        'FATAL': 'üíÄ',
        'CRITICAL': 'üî•',
        'WARN': '‚ö†Ô∏è',
        'WARNING': '‚ö†Ô∏è',
        'INFO': '‚ÑπÔ∏è',
        'DEBUG': 'üêõ'
    }
    return emoji_map.get(level, 'üìù')

def _get_status_emoji(self, status_code):
    """Get emoji for HTTP status code"""
    code = int(status_code) if status_code.isdigit() else 0
    if 200 <= code < 300:
        return '‚úÖ'
    elif 300 <= code < 400:
        return 'üîÑ'
    elif 400 <= code < 500:
        return '‚ö†Ô∏è'
    elif 500 <= code < 600:
        return '‚ùå'
    else:
        return '‚ùì'

def network_scan(self, query=None):
    """Scan network for devices"""
    if not NMAP_AVAILABLE:
        return "‚ùå nmap not installed. Run: pip install python-nmap"
    
    if query:
        nlp = self.extract_params(query, "network_scan")
    else:
        nlp = {"target": "none", "port_range": "none"}
    
    target = nlp["target"] if nlp["target"] != "none" else "192.168.1.0/24"
    port_range = nlp["port_range"] if nlp["port_range"] != "none" else "1-1000"
    
    try:
        nm = nmap.PortScanner()
        nm.scan(hosts=target, arguments=f"-p {port_range} -sS")
        
        results = []
        for host in nm.all_hosts():
            if nm[host].state() == "up":
                open_ports = []
                for proto in nm[host].all_protocols():
                    ports = nm[host][proto].keys()
                    for port in ports:
                        if nm[host][proto][port]['state'] == 'open':
                            open_ports.append(str(port))
                
                if open_ports:
                    results.append(f"üñ•Ô∏è {host}: Ports {', '.join(open_ports)} open")
                else:
                    results.append(f"üñ•Ô∏è {host}: No open ports")
        
        return f"üåê Network Scan Results:\n" + "\n".join(results) if results else "‚ùå No hosts found"
    except Exception as e:
        return f"‚ùå Network scan failed: {e}"

def ssh_execute(self, query=None):
    """Execute command via SSH"""
    if query:
        nlp = self.extract_params(query, "ssh_execute")
    else:
        nlp = {"host": "none", "command": "none", "username": "none", "password": "none"}
    
    host = nlp["host"] if nlp["host"] != "none" else input("Host: ")
    command = nlp["command"] if nlp["command"] != "none" else input("Command: ")
    username = nlp["username"] if nlp["username"] != "none" else input("Username: ")
    password = nlp["password"] if nlp["password"] != "none" else input("Password: ")
    
    try:
        client = paramiko.SSHClient()
        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        client.connect(host, username=username, password=password)
        
        stdin, stdout, stderr = client.exec_command(command)
        output = stdout.read().decode()
        error = stderr.read().decode()
        
        client.close()
        
        if output:
            return f"üñ•Ô∏è SSH Output:\n{output}"
        elif error:
            return f"‚ùå SSH Error:\n{error}"
        else:
            return "‚úÖ Command executed (no output)"
    except Exception as e:
        return f"‚ùå SSH failed: {e}"

# ========== AUTOMATION ==========

def web_scrape(self, query=None):
    """Scrape website content"""
    if query:
        nlp = self.extract_params(query, "web_scrape")
    else:
        nlp = {"url": "none", "element": "none", "output": "none"}
    
    url = nlp["url"] if nlp["url"] != "none" else input("URL: ")
    element = nlp["element"] if nlp["element"] != "none" else "p"  # paragraph tags by default
    output = nlp["output"] if nlp["output"] != "none" else None
    
    try:
        from bs4 import BeautifulSoup
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        elements = soup.find_all(element)
        text = "\n".join([elem.get_text().strip() for elem in elements[:10]])  # First 10
        
        if output:
            with open(output, 'w', encoding='utf-8') as f:
                f.write(text)
            return f"‚úÖ Scraped content saved to {output}"
        else:
            return f"üåê Scraped Content:\n{text}"
    except Exception as e:
        return f"‚ùå Web scraping failed: {e}"

def file_operations(self, query=None):
    """File operations (copy, move, delete, rename)"""
    if query:
        nlp = self.extract_params(query, "file_operations")
    else:
        nlp = {"operation": "none", "path": "none", "destination": "none"}
    
    operation = nlp["operation"] if nlp["operation"] != "none" else input("Operation (copy/move/delete/rename): ")
    path = nlp["path"] if nlp["path"] != "none" else input("Source path: ")
    destination = nlp["destination"] if nlp["destination"] != "none" else input("Destination path: ") if operation != "delete" else None
    
    try:
        if operation == "copy":
            if os.path.isdir(path):
                shutil.copytree(path, destination)
            else:
                shutil.copy2(path, destination)
            return f"‚úÖ Copied to {destination}"
        
        elif operation == "move":
            shutil.move(path, destination)
            return f"‚úÖ Moved to {destination}"
        
        elif operation == "delete":
            if os.path.isdir(path):
                shutil.rmtree(path)
            else:
                os.remove(path)
            return f"‚úÖ Deleted {path}"
        
        elif operation == "rename":
            os.rename(path, destination)
            return f"‚úÖ Renamed to {destination}"
        
        else:
            return "‚ùå Invalid operation"
    except Exception as e:
        return f"‚ùå File operation failed: {e}"