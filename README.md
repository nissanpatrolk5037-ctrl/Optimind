<p align="center">
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" width="90" />
</p>

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&size=30&duration=4000&color=6C63FF&center=true&vCenter=true&width=800&lines=Optimind;Advanced+Multi-Modal+AI+System;Locally-Hosted+Intelligent+Agent;Secure+and+Extensible+Architecture" alt="Typing SVG" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-Core%20Engine-6366F1?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/AI-Hybrid%20Intelligence-8B5CF6?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Execution-Offline%20First-22C55E?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Security-Zero%20Trust-EF4444?style=for-the-badge" />
</p>

---

## ğŸ§  What Is **Optimind**?

**Optimind** is a fully engineered **personal intelligence system** â€” not a chatbot.

It is designed to:

* ğŸ–¥ï¸ Run **locally**
* ğŸ”Œ Work **offline-first**
* â˜ï¸ Scale **online when needed**
* ğŸ” Stay **fully under your control**

> **AI should be owned â€” not rented.**

---

## ğŸ§¬ Design Philosophy

```mermaid
flowchart LR
    Control --> Privacy --> Speed --> Intelligence --> Control
```

* **Control over execution**
* **Privacy by default**
* **Speed without compromise**
* **Modular intelligence**

---

## ğŸš€ Newly Added Features

### ğŸ”§ Plugin System

* Dynamic plugin loading & management
* Voice-activated plugin triggers
* Interactive plugin manager (`p` key or voice)
* Hot-reload without restart
* Isolated execution per plugin

### ğŸ™ï¸ Adaptive Whisper STT

* Smart model selection by audio length
* RAM-aware loading (8GB+ optimized)
* Real-time VAD & silence endpointing

### ğŸ§  Smart Parser & Automation

* Hybrid LLM routing (local + cloud)
* Automation task detection
* Automatic code execution
* Context-aware responses

### ğŸ›¡ï¸ Enhanced Security Layers

* Password guard with secure validation
* Age verification system
* Content filtering
* Secure API session handling

### ğŸ“ File & Data Processing

* CSV analysis & AI reports
* Word clouds with custom masks
* DOCX / PDF generation
* QR code generation

### ğŸ¨ Media Creation Suite

* AI image generation (Pollinations)
* Audio generation (Melody)
* Screen & live camera analysis
* Object detection & recognition

---

## ğŸ§  System Architecture

flowchart TB
    %% ========== START & AUTHENTICATION ==========
    Start((Start)) --> Auth[Authentication Layer]
    
    subgraph Auth["ğŸ”’ Security & Authentication"]
        direction TB
        PW[Password Guard] --> Age[Age Verification]
        Age --> Clap[Clap Detection]
    end
    
    Auth --> Boot[System Boot]
    
    %% ========== CORE SENSOR INPUTS ==========
    Boot --> Sensors
    
    subgraph Sensors["ğŸ“¡ Input Sensors"]
        direction LR
        Microphone[ğŸ¤ Voice Input] --> Whisper[Whisper STT]
        Camera[ğŸ“· Live Camera] --> YOLO[YOLO Detection]
        Screen[ğŸ–¥ï¸ Screen Capture] --> OCR[Screen Analysis]
    end
    
    Whisper -->|Adaptive Models<br/>Tinyâ†’Large| STT_Output[Transcribed Text]
    YOLO -->|Object Detection| Vision_Output
    OCR -->|Text Extraction| Screen_Output
    
    STT_Output -->|Speech| InputHub[Input Processing Hub]
    Vision_Output -->|Vision| InputHub
    Screen_Output -->|Screen| InputHub
    
    %% ========== PLUGIN ECOSYSTEM ==========
    InputHub --> PluginRouter[Plugin Router]
    
    subgraph Plugins["ğŸ”Œ Plugin Ecosystem"]
        direction TB
        
        subgraph MediaPlugins["ğŸ¨ Media Plugins"]
            M1[Image Generation]
            M2[QR Code Generator]
            M3[Word Cloud]
            M4[Audio Generation]
            M5[Screen Analysis]
        end
        
        subgraph APIPlugins["ğŸŒ API Integrations"]
            A1[AWS Control]
            A2[Google Services]
            A3[Discord/WhatsApp]
            A4[Slack/Twitter]
            A5[Azure/GitHub]
        end
        
        subgraph UtilityPlugins["ğŸ› ï¸ Utility Plugins"]
            U1[File Operations]
            U2[Data Analysis]
            U3[Web Scraping]
            U4[System Control]
            U5[Security Tools]
        end
        
        subgraph AIPlugins["ğŸ¤– AI Services"]
            AI1[OpenAI GPT]
            AI2[Translation]
            AI3[Wikipedia]
            AI4[PDF/OCR]
        end
    end
    
    PluginRouter -->|Media Triggers| MediaPlugins
    PluginRouter -->|API Triggers| APIPlugins
    PluginRouter -->|Utility Triggers| UtilityPlugins
    PluginRouter -->|AI Triggers| AIPlugins
    
    %% ========== CORE AI PROCESSING ==========
    InputHub -->|No Plugin Match| SmartParser[Smart Parser]
    
    subgraph ParserLogic["ğŸ§  Smart Parser Logic"]
        direction TB
        Decision{Is Task Automation?}
        Decision -->|Yes| AutoCode[Auto-Coder Engine]
        Decision -->|No| ChatMode[Chat Mode]
    end
    
    SmartParser --> ParserLogic
    
    %% ========== LLM INTEGRATION ==========
    ChatMode --> LLMRouter[LLM Router]
    
    subgraph LLMs["ğŸ§¬ Multi-LLM Architecture"]
        direction LR
        
        subgraph Online["âš¡ Online (Fast)"]
            Groq[Groq LLaMA 70B]
            Groq -->|API| GroqCloud[Cloud API]
        end
        
        subgraph Offline["ğŸ’¾ Offline (Local)"]
            Local1[DeepSeek Local]
            Local2[Gemma 2B]
            Local3[Custom Models]
        end
    end
    
    LLMRouter -->|Internet Available| Online
    LLMRouter -->|No Internet| Offline
    
    %% ========== EXECUTION & OUTPUT ==========
    AutoCode -->|Python Code| CodeExec[Code Executor]
    MediaPlugins --> MediaExec[Media Engine]
    APIPlugins --> APIExec[API Gateway]
    UtilityPlugins --> UtilExec[Utility Engine]
    AIPlugins --> AIExec[AI Processor]
    LLMs --> ResponseGen[Response Generator]
    
    %% ========== MEMORY & LOGGING ==========
    ResponseGen --> Memory[JSON Memory System]
    CodeExec --> Memory
    MediaExec --> Memory
    APIExec --> Memory
    UtilExec --> Memory
    AIExec --> Memory
    
    Memory --> Logging[ğŸ“Š Conversation Log]
    
    %% ========== FINAL OUTPUTS ==========
    ResponseGen --> TTS[Typecast TTS Engine]
    MediaExec --> MediaOutput[Media Outputs]
    CodeExec --> Terminal[Terminal Output]
    APIExec --> Network[Network Responses]
    UtilExec --> System[System Changes]
    AIExec --> AIOutput[AI Responses]
    
    TTS -->|Voice| Speaker["ğŸ”Š Audio Output"]
    MediaOutput -->|Images/Files| Display["ğŸ–¼ï¸ Visual Output"]
    Terminal -->|Code Results| Console["ğŸ’» Console"]
    Network -->|API Results| Status["ğŸ“¡ Network Status"]
    System -->|Changes| Feedback["ğŸ”„ System Feedback"]
    AIOutput -->|Text| ChatDisplay["ğŸ’­ Chat Display"]
    
    %% ========== FEEDBACK LOOP ==========
    Speaker --> UserFeedback[User Interaction]
    Display --> UserFeedback
    Console --> UserFeedback
    Status --> UserFeedback
    Feedback --> UserFeedback
    ChatDisplay --> UserFeedback
    
    UserFeedback --> Sensors
    
    %% ========== STYLES ==========
    classDef start fill:#2E8B57,stroke:#333,stroke-width:2px,color:#fff
    classDef security fill:#B22222,stroke:#333,stroke-width:1px,color:#fff
    classDef input fill:#4169E1,stroke:#333,stroke-width:1px,color:#fff
    classDef plugin fill:#8A2BE2,stroke:#333,stroke-width:1px,color:#fff
    classDef ai fill:#FF4500,stroke:#333,stroke-width:1px,color:#fff
    classDef llm fill:#20B2AA,stroke:#333,stroke-width:1px,color:#fff
    classDef exec fill:#32CD32,stroke:#333,stroke-width:1px,color:#000
    classDef output fill:#FFD700,stroke:#333,stroke-width:1px,color:#000
    classDef memory fill:#9370DB,stroke:#333,stroke-width:1px,color:#fff
    
    class Start start
    class Auth,PW,Age,Clap security
    class Sensors,Microphone,Camera,Screen,Whisper,YOLO,OCR input
    class Plugins,MediaPlugins,APIPlugins,UtilityPlugins,AIPlugins plugin
    class SmartParser,ParserLogic,Decision ai
    class LLMs,Online,Offline,Groq,Local1,Local2,Local3 llm
    class CodeExec,MediaExec,APIExec,UtilExec,AIExec exec
    class Speaker,Display,Console,Status,Feedback,ChatDisplay output
    class Memory,Logging memory

---

## âš™ï¸ Intelligence Stack

### ğŸ™ï¸ Voice Layer

* Adaptive Whisper STT
* Typecast TTS
* Clap detection for hands-free activation

### ğŸ§  Language Models

**Cloud**

* Groq (LLaMA 70B)

**Local**

* DeepSeek 7B
* Gemma 7B
* LLaMA 8B
* Qwen 7B

Automatic routing based on task & connectivity.

---

## ğŸ”Œ Plugin Architecture

* Metadata-based plugins
* Trigger-driven activation
* Isolated execution
* Hot reload
* Plugin manager UI

---

## ğŸ” Security Core

```mermaid
sequenceDiagram
    User->>Gateway: Request
    Gateway->>Security: Validate
    Security->>Database: Encrypt
    Database-->>Gateway: Verified
    Gateway-->>User: Access Granted
```

* Password protection
* Age verification
* Content filtering
* Local-first data storage


---
## ğŸ—ï¸ Project Structure

```text
optimind/
â”œâ”€â”€ main.py
â”œâ”€â”€ auto_coder.py
â”œâ”€â”€ memory.py
â”œâ”€â”€ plugin.py
â”œâ”€â”€ api_integrations.py
â”œâ”€â”€ speak.py
â”œâ”€â”€ clap.py
â”œâ”€â”€ age.py
â”œâ”€â”€ pwd_guard.py
â”œâ”€â”€ conversation_memory.json
â”œâ”€â”€ live_camera.py
â”œâ”€â”€ live_screen.py
â”œâ”€â”€ melody.py
â”œâ”€â”€ triggers.py
â”œâ”€â”€ local_llm_exec.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ security_db
|   â”œâ”€â”€ age_guard.db
|   â”œâ”€â”€ sys_guard.db
â”œâ”€â”€ whisper-cpp
|   â”œâ”€â”€ whisper-cpp-downloads
â””â”€â”€ plugins/
    â”œâ”€â”€ calculator_plugin.py
    â”œâ”€â”€ joke_plugin.py
    â”œâ”€â”€ sample_weather_plugin.py

```

---

## ğŸ”§ Plugin Development

```python
plugin_info = {
    "name": "My Plugin",
    "version": "1.0.0",
    "author": "You",
    "triggers": ["my command"]
}

def plugin_function(text, speak):
    speak("Plugin executed")
    return text
```

---

## ğŸ› ï¸ Troubleshooting

* **Whisper not found** â†’ Check model paths
* **No audio input** â†’ Verify mic permissions
* **Slow performance** â†’ Use smaller models

---

## ğŸ“„ License

Custom License

---

## ğŸ´ Final Words

This repository is **not a demo**.

It is a **foundation for personal AI sovereignty** â€” intelligence you own, control, and evolve.

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=0:6366F1,100:8B5CF6&height=200&section=footer" />
</p>
